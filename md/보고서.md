# ClinicalTrials.gov Outcomes 정규화 프로젝트 보고서

## 1. 개발 목적

### 1.1 프로젝트 개요

ClinicalTrials.gov에서 수집한 Primary/Secondary Outcome 데이터를 정규화하여 구조화된 형태로 변환하는 프로젝트입니다.

### 1.2 목표

- **Primary/Secondary outcome과 time frame을 한 세트로 정규화**
- **Outcome 정규화**: `measure_raw` → `measure_clean` (텍스트 클리닝)
- **Time frame 정규화**: `time_frame_raw` → `time_value_main` + `time_unit_main` (숫자 + 단위)
- **애매한 데이터는 모두 실패 처리**하여 정확성 확보

### 1.3 궁극적 목표 (2차 정규화)

- Outcome dictionary 기반 정규화 (`measure_norm`, `measure_code`)
- Time, unit으로 깔끔하게 숫자 + unit 형태로 분리
- 정규화된 데이터를 활용한 분석 및 검색 기능 제공

### 1.4 핵심 원칙

1. **원본 데이터 보존**: `outcome_raw` 테이블에 원본 데이터 완전 보존
2. **엄격한 파싱**: 단일 시점만 허용, 복수 시점/범위는 실패 처리
3. **단계별 정규화**: 1차(규칙 기반) → 2차(사전 기반) → 3차(검증)

---

## 2. 데이터 수집

### 2.1 데이터 소스

- **API**: ClinicalTrials.gov API v2
- **엔드포인트**: `https://clinicaltrials.gov/api/v2/studies`
- **쿼리 조건**: Alzheimer's Disease
- **데이터 형식**: JSON

### 2.2 수집 대상

1. **Outcomes 데이터**

   - `primaryOutcomes`: Primary outcome 목록
   - `secondaryOutcomes`: Secondary outcome 목록
   - 각 outcome의 `measure`, `timeFrame`, `description` 필드

2. **Party 정보** (기관/담당자)
   - `LEAD_SPONSOR`: 주관 스폰서
   - `ORGANIZATION`: 연구 기관
   - `OFFICIAL`: 담당자 정보

### 2.3 수집 프로세스

- API pagination 처리 (nextPageToken 사용)
- 배치 삽입 (1000건 단위)
- 중복 방지 처리 (ON CONFLICT)
- 원본 JSON 보존 (raw_json 컬럼)

### 2.4 수집 결과

- **총 Studies**: 3,866건
- **총 Outcomes**: 25,591건
  - Primary: 약 9,500건
  - Secondary: 약 16,000건

---

## 3. DB Table 구조

### 3.1 테이블 목록

#### 3.1.1 `outcome_raw` (원본 데이터 보존)

**주요 컬럼:**

- `nct_id`: Study 식별자
- `outcome_type`: PRIMARY 또는 SECONDARY
- `outcome_order`: Outcome 순서
- `measure_raw`: 원본 measure 텍스트
- `description_raw`: 원본 description 텍스트
- `time_frame_raw`: 원본 time frame 텍스트
- `raw_json`: 원본 JSON 데이터 (완전 보존)
- `ingested_at`: 수집 시각

**목적**: 원본 데이터 완전 보존 (재처리 가능)

#### 3.1.2 `outcome_normalized` (정규화된 데이터)

**주요 컬럼:**

- `measure_raw`: 원본 measure 텍스트
- `measure_clean`: 1차 정규화 결과 (텍스트 클리닝)
- `measure_abbreviation`: 괄호 안 약어 추출 결과
- `measure_norm`: 2차 정규화 예정 (사전 매핑)
- `measure_code`: 사전 매핑 코드
- `time_frame_raw`: 원본 time frame 텍스트
- `time_value_main`: 파싱된 숫자 (소수점 지원)
- `time_unit_main`: 파싱된 단위 (day/week/month/year/hour)
- `change_from_baseline_flag`: Baseline 변경 여부 플래그
- `failure_reason`: 실패 원인 ('MEASURE_FAILED', 'TIMEFRAME_FAILED', 'BOTH_FAILED', NULL=성공)

**목적**: 정규화된 데이터 저장

#### 3.1.3 `outcome_normalized_success` (성공 케이스)

- `outcome_normalized`와 동일한 구조
- 정규화 성공한 데이터만 저장
- 조건: `measure_abbreviation IS NOT NULL AND time_value_main IS NOT NULL AND time_unit_main IS NOT NULL`
- measure 약어 추출 성공 AND time_frame 추출 성공

#### 3.1.4 `outcome_normalized_failed` (실패 케이스)

- 정규화 실패한 데이터 저장
- 조건: `failure_reason IS NOT NULL`
- `failure_reason` 필드로 실패 원인 구분:
  - `MEASURE_FAILED`: measure 약어 추출 실패
  - `TIMEFRAME_FAILED`: time_frame 추출 실패
  - `BOTH_FAILED`: 둘 다 실패

#### 3.1.5 Success/Failed 분리 기준

**Success 기준:**

- `measure_abbreviation IS NOT NULL` (괄호 안 약어 추출 성공)
- `time_value_main IS NOT NULL AND time_unit_main IS NOT NULL` (time_frame 추출 성공)
- 둘 다 성공해야 success

**Failed 기준:**

- `failure_reason` 필드로 구분:
  - `MEASURE_FAILED`: measure 약어 추출 실패
  - `TIMEFRAME_FAILED`: time_frame 추출 실패
  - `BOTH_FAILED`: 둘 다 실패

#### 3.1.6 `study_party_raw` (기관/담당자 정보)

**주요 컬럼:**

- `nct_id`: Study 식별자
- `party_type`: LEAD_SPONSOR, ORGANIZATION, OFFICIAL
- `name_raw`: 기관/담당자 이름
- `affiliation_raw`: 소속 정보
- `role_raw`: 역할
- `class_raw`: 분류 (INDUSTRY, NIH, FED 등)
- `location_raw`: 위치 정보 (JSON)

**목적**: 기관/담당자별 패턴 분석 및 원인 분석

#### 3.1.7 `outcome_measure_dict` (Measure 사전)

**주요 컬럼:**

- `measure_code`: Measure 코드 (PK)
- `canonical_name`: 표준 이름
- `abbreviation`: 약어
- `keywords`: 키워드 (세미콜론 구분)
- `domain`: 도메인 (Cognition, Function 등)
- `unit_type`: 단위 타입 (Score 등)
- `score_direction`: 점수 방향 (Higher = worse/better)

**목적**: 2차 정규화 시 measure 매핑용 사전

---

## 4. 정규식 패턴

### 4.1 TimeFrame 파싱 패턴

#### 4.1.1 기본 원칙

- **단일 시점만 허용** (최우선 룰)
- 복수 시점, 범위는 모두 실패 처리
- 쉼표(,), "and", "to/through", 하이픈(-) 포함 시 실패

#### 4.1.2 파싱 가능한 패턴

**1. Baseline 포함**

- 패턴: baseline 단어 포함
- 예: "Baseline, Week 16" → change_from_baseline_flag = TRUE

**2. At Day/Week/Month N**

- 패턴: "At" + 단위 + 숫자
- 예: "At Week 14" → 14, week

**3. Day/Month/Week N 단독**

- 패턴: 단위 + 숫자
- 예: "Day 1", "Month 3", "Week 12" → 1, day / 3, month / 12, week

**4. 숫자 + 단위 (하이픈 포함)**

- 패턴: 숫자 + 하이픈(선택) + 단위
- 예: "26 weeks", "96-week", "21-months", "48 hr" → 26, week / 96, week / 21, month / 48, hour

**5. Year N**

- 패턴: "year" + 숫자
- 예: "Year 3.5" → 3.5, year (소수점 지원)

**6. 텍스트 숫자**

- 패턴: 텍스트 숫자(one, two 등) + 단위
- 예: "Two years", "eight weeks" → 2, year / 8, week

**7. Up to N**

- 패턴: "up to" + 숫자 + 단위(선택)
- 예: "up to 72 hours" → 72, hour

#### 4.1.3 실패 처리 패턴

**복수 시점 감지:**

- 쉼표(,) 포함: "baseline time,week6,week 12"
- "and" 연결: "Weeks 6 and 12", "Months 3 and 6"
- 범위: "Day 1 through 7", "3-5 years", "Day 15-19"
- 콜론(:) 포함: "Day 1: Pre-dose and 2, 4, 8..."
- 음수 시점: "Week -4"

### 4.2 Measure 파싱 패턴

#### 4.2.1 텍스트 클리닝

- 연속 공백 → 단일 공백
- 오타 교정 (extention → extension 등)
- 앞뒤 공백 제거

#### 4.2.2 약어 추출

- 패턴: 괄호 안의 약어 추출
- 예: "(TMT-A/B)", "(pharmacodynamics)"
- 소문자, 슬래시(/) 포함 지원

### 4.3 Description 파싱 패턴

#### 4.3.1 Change from Baseline 감지

- 패턴: "change from baseline" 또는 "difference from baseline"
- `change_from_baseline_flag = TRUE` 설정

---

## 5. 1차 파싱 결과

### 5.1 전체 통계

| 구분            | 건수   | 비율 |
| --------------- | ------ | ---- |
| **총 Studies**  | 3,866  | 100% |
| **총 Outcomes** | 25,591 | 100% |
| **정규화 성공** | -      | -    |
| **정규화 실패** | -      | -    |

**성공 기준**: measure 약어 추출 성공 AND time_frame 추출 성공

**참고**:

- measure 약어 추출 성공률: 약 22.4% (5,700건)
- time_frame 추출 성공률: 약 52.3% (13,388건)
- **둘 다 성공해야 정규화 성공**이므로, 실제 성공률은 더 낮을 것으로 예상됨

### 5.2 Outcome Type별 통계

#### Primary Outcomes

- **정규화 성공**: -건 (measure 약어 추출 성공 AND time_frame 추출 성공)
- **정규화 실패**: -건 (failure_reason으로 구분)

#### Secondary Outcomes

- **정규화 성공**: -건 (measure 약어 추출 성공 AND time_frame 추출 성공)
- **정규화 실패**: -건 (failure_reason으로 구분)

### 5.3 Measure 파싱 결과

#### 텍스트 클리닝

- **성공**: 25,591건 (100%)
- 모든 measure_raw에 대해 클리닝 수행

#### 약어 추출

- **약어 포함 Outcomes**: 약 5,700건 (22.4%)
- 괄호 안 약어 추출 성공
- **성공률이 낮은 이유**: 많은 measure가 괄호 안 약어 없이 일반 텍스트로만 작성됨

### 5.4 TimeFrame 파싱 결과

#### 파싱 성공 케이스

- **파싱 성공 Outcomes**: 약 13,388건 (52.3%)
- **time_value_main + time_unit_main 추출 성공**

#### 파싱 실패 케이스

- **복수 시점**: 쉼표, "and" 연결 등
- **범위 표현**: "Day 1 through 7", "3-5 years" 등
- **비표준 표현**: "% of exact responses", "The time to respond" 등
- **복잡한 조건**: "3 Days in each of the 4 dosing session" 등

### 5.5 1차 정규화 성공률 분석

**성공 기준**: measure 약어 추출 성공 AND time_frame 추출 성공

- **measure 약어 추출 성공률**: 약 22.4% (5,700건)
- **time_frame 추출 성공률**: 약 52.3% (13,388건)
- **예상 정규화 성공률**: 두 조건을 모두 만족해야 하므로, **약 20% 미만**으로 예상됨

### 5.6 Change from Baseline 플래그

- **플래그 설정**: 5,411건 (21.1%)
- timeFrame의 "baseline" 패턴 또는 description의 "change from baseline" 패턴 감지

### 5.7 데이터 분리 결과

#### `outcome_normalized_success`

- 완벽하게 정규화된 데이터
- `measure_abbreviation IS NOT NULL` (약어 추출 성공)
- `time_value_main IS NOT NULL AND time_unit_main IS NOT NULL` (time_frame 추출 성공)

#### `outcome_normalized_failed`

- 정규화 실패 데이터
- `failure_reason` 필드로 구분:
  - `MEASURE_FAILED`: measure 약어 추출 실패
  - `TIMEFRAME_FAILED`: time_frame 추출 실패
  - `BOTH_FAILED`: 둘 다 실패

---

## 6. 주요 성과

### 6.1 데이터 품질

- **정규화 성공률**: measure 약어 추출 성공 AND time_frame 추출 성공 기준
- **성공률이 낮은 이유**: measure 약어 추출 성공률이 22.4%로 낮아, 둘 다 성공하는 경우는 더욱 제한적
- **원본 데이터 보존**: 재처리 및 규칙 개선 가능
- **단계별 분리**: 성공/실패 데이터 명확히 구분 (failure_reason으로 원인 파악)

### 6.2 기술적 성과

- **엄격한 파싱 룰**: 단일 시점만 허용하여 정확성 확보
- **패턴 기반 분석**: 정규식 패턴으로 체계적 파싱
- **확장 가능한 구조**: 2차 정규화를 위한 사전 구조 준비

### 6.3 향후 계획

1. **정규식 개선**: 실패 케이스 분석 후 패턴 추가
2. **2차 정규화**: Dictionary 기반 measure 매핑

---

## 7. 파일 구조

### 7.1 주요 스크립트

- `collect_outcomes.py`: 데이터 수집
- `normalize_phase1.py`: 1차 정규화
- `separate_normalized_data.py`: 데이터 분리 (성공/실패/제외)
- `diagnose_all.py`: 데이터 진단 및 분석
- `normalization_patterns.py`: 정규식 패턴 정의

### 7.2 데이터베이스

- `schema.sql`: 테이블 스키마 정의
- `query_normalized_results.sql`: 정규화 결과 조회 쿼리

---

## 8. 결론

1차 정규화는 **measure 약어 추출 성공 AND time_frame 추출 성공**을 기준으로 합니다.

**현황 분석**:

- measure 약어 추출 성공률: 약 22.4% (5,700건)
- time_frame 추출 성공률: 약 52.3% (13,388건)
- **실제 정규화 성공률**: 두 조건을 모두 만족해야 하므로, measure 약어 추출 성공률에 의해 제한됨

**핵심 이슈**:

- 많은 measure가 괄호 안 약어 없이 일반 텍스트로만 작성되어 약어 추출이 어려움
- 향후 Dictionary 기반 매핑(2차 정규화)을 통해 성공률 향상 필요

**성과**:

- 엄격한 기준으로 정확한 데이터만 정규화
- 실패 원인을 failure_reason으로 명확히 구분
- 원본 데이터 보존으로 재처리 및 규칙 개선 가능

**핵심 성과:**

- 원본 데이터 완전 보존
- 엄격한 파싱 룰로 정확성 확보
- 단계별 정규화 구조 구축
- 패턴 기반 분석 체계 구축

**다음 단계:**

- 실패 케이스 심층 분석
- 정규식 패턴 추가 및 개선
- 2차 정규화 (Dictionary 기반) 준비
