"""
DB ì¿¼ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜ ëª¨ë“ˆ

ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ì™€ ë¶„ì„ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ
ì •ê·œí™” íŒ¨í„´ì€ normalization_patterns ëª¨ë“ˆì„ ì‚¬ìš©
"""

import os
from typing import Dict, List
from collections import defaultdict
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv
from normalization_patterns import (
    timeframe_patterns,
    measure_patterns,
    description_patterns,
    get_sql_parseable_conditions,
    get_sql_unparseable_condition
)

load_dotenv()

# Excel ë¦¬í¬íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ì €ì¥ (ì „ì—­ ë³€ìˆ˜)
# ì´ ë³€ìˆ˜ëŠ” diagnose_all.pyì—ì„œ ì´ˆê¸°í™”ë¨
excel_data = {}


def set_excel_data(data_dict: Dict):
    """Excel ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ì„¤ì •"""
    global excel_data
    excel_data = data_dict


def get_unparseable_sql_conditions() -> str:
    """
    SQL ì¿¼ë¦¬ì—ì„œ ì‚¬ìš©í•  íŒŒì‹± ë¶ˆê°€ëŠ¥ ì¡°ê±´ ë°˜í™˜
    
    Returns:
        íŒŒì‹± ë¶ˆê°€ëŠ¥í•œ íŒ¨í„´ì„ ì œì™¸í•˜ëŠ” SQL ì¡°ê±´ ë¬¸ìì—´
    """
    conditions = get_sql_parseable_conditions()
    
    # ëª¨ë“  íŒŒì‹± ê°€ëŠ¥í•œ íŒ¨í„´ì„ NOT ì¡°ê±´ìœ¼ë¡œ ê²°í•©
    not_conditions = [
        f"NOT (o.time_frame_raw ~* '{pattern_regex}')"
        for pattern_regex in conditions.values()
    ]
    
    return " AND ".join(not_conditions)


def analyze_timeframe_patterns(conn):
    """timeFrame íŒ¨í„´ ë¶„ì„ (normalization_patterns ì‚¬ìš©)"""
    print("\n" + "=" * 80)
    print("2. timeFrame íŒ¨í„´ ë¶„ì„")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # ëª¨ë“  timeFrame ê°€ì ¸ì˜¤ê¸°
        cur.execute("""
            SELECT time_frame_raw 
            FROM outcome_raw 
            WHERE time_frame_raw IS NOT NULL AND time_frame_raw != ''
        """)
        timeframes = [row['time_frame_raw'] for row in cur.fetchall()]
        
        total = len(timeframes)
        print(f"\nğŸ“Š ì´ timeFrame ë°ì´í„°: {total:,}ê±´")
        
        # íŒ¨í„´ ë¶„ë¥˜ (normalization_patterns ì‚¬ìš©)
        pattern_mapping = {
            'baseline': 'Baseline í¬í•¨ (change_from_baseline)',
            'at_day_week_month': 'ê¸°ê°„ íŒ¨í„´ (At Day/Week/Month N)',
            'day_month_week_standalone': 'ê¸°ê°„ íŒ¨í„´ (Day/Month/Week N ë‹¨ë…)',
            'day_to_through': 'ê¸°ê°„ íŒ¨í„´ (Day N to/through M)',
            'for_period': 'ê¸°ê°„ íŒ¨í„´ (For N Months/Weeks/Days)',
            'at_months_and': 'ê¸°ê°„ íŒ¨í„´ (At Months N and M)',
            'text_number': 'ê¸°ê°„ íŒ¨í„´ (í…ìŠ¤íŠ¸ ìˆ«ì+ë‹¨ìœ„)',
            'period': 'ê¸°ê°„ íŒ¨í„´ (ìˆ«ì+ë‹¨ìœ„)',
            'year': 'ê¸°ê°„ íŒ¨í„´ (Year N)',
            'upto': 'ê¸°ê°„ íŒ¨í„´ (Up to)',
            'through': 'ê¸°ê°„ íŒ¨í„´ (Through)',
            'percent': 'ì‘ë‹µë¥ /ë¹„ìœ¨',
            'time': 'ì‹œê°„/ì†ë„',
            'unparseable': 'ê¸°íƒ€/ë¶ˆëª…í™•'
        }
        
        patterns = {name: 0 for name in pattern_mapping.values()}
        examples = defaultdict(list)
        
        for tf in timeframes:
            pattern_type = timeframe_patterns.classify_timeframe(tf)
            pattern_name = pattern_mapping.get(pattern_type, 'ê¸°íƒ€/ë¶ˆëª…í™•')
            patterns[pattern_name] += 1
            
            if len(examples[pattern_name]) < 5:
                examples[pattern_name].append(tf)
        
        print(f"\nğŸ“ˆ íŒ¨í„´ ë¶„ë¥˜ ê²°ê³¼:")
        for pattern, count in patterns.items():
            pct = count / total * 100 if total > 0 else 0
            print(f"  â€¢ {pattern}: {count:,}ê±´ ({pct:.1f}%)")
        
        # ì„±ê³µ/ì‹¤íŒ¨ ìš”ì•½
        success_patterns = [
            'Baseline í¬í•¨ (change_from_baseline)',
            'ê¸°ê°„ íŒ¨í„´ (At Day/Week/Month N)',
            'ê¸°ê°„ íŒ¨í„´ (Day/Month/Week N ë‹¨ë…)',
            'ê¸°ê°„ íŒ¨í„´ (Day N to/through M)',
            'ê¸°ê°„ íŒ¨í„´ (For N Months/Weeks/Days)',
            'ê¸°ê°„ íŒ¨í„´ (At Months N and M)',
            'ê¸°ê°„ íŒ¨í„´ (í…ìŠ¤íŠ¸ ìˆ«ì+ë‹¨ìœ„)',
            'ê¸°ê°„ íŒ¨í„´ (ìˆ«ì+ë‹¨ìœ„)',
            'ê¸°ê°„ íŒ¨í„´ (Year N)',
            'ê¸°ê°„ íŒ¨í„´ (Up to)',
            'ê¸°ê°„ íŒ¨í„´ (Through)'
        ]
        success_count = sum(patterns[p] for p in success_patterns)
        failure_count = patterns['ê¸°íƒ€/ë¶ˆëª…í™•'] + patterns['ì‘ë‹µë¥ /ë¹„ìœ¨'] + patterns['ì‹œê°„/ì†ë„']
        
        print(f"\nğŸ¯ íŒŒì‹± ê°€ëŠ¥ì„± ìš”ì•½:")
        print(f"  âœ… íŒŒì‹± ê°€ëŠ¥ (ê¸°ê°„ íŒ¨í„´ + Baseline í¬í•¨): {success_count:,}ê±´ ({success_count/total*100:.1f}%)")
        print(f"  âŒ íŒŒì‹± ì–´ë ¤ì›€ (ê¸°íƒ€/ë¶ˆëª…í™•): {failure_count:,}ê±´ ({failure_count/total*100:.1f}%)")
        
        # Excel ë°ì´í„° ì €ì¥
        for pattern, count in patterns.items():
            excel_data['timeframe_patterns'].append({
                'pattern': pattern,
                'count': count,
                'percentage': count / total * 100 if total > 0 else 0
            })
        
        excel_data['summary']['timeframe_parseable'] = success_count
        excel_data['summary']['timeframe_unparseable'] = failure_count
        excel_data['summary']['timeframe_total'] = total
        
        print(f"\nğŸ“ íŒ¨í„´ë³„ ì˜ˆì‹œ (ìµœëŒ€ 3ê°œ):")
        for pattern, ex_list in examples.items():
            if ex_list:
                print(f"\n  {pattern}:")
                for ex in ex_list[:3]:
                    print(f"    - {ex[:80]}..." if len(ex) > 80 else f"    - {ex}")

