"""
ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ ÏßÑÎã® Ïä§ÌÅ¨Î¶ΩÌä∏

outcome_raw Îç∞Ïù¥ÌÑ∞Î•º Ï¢ÖÌï©Ï†ÅÏúºÎ°ú Î∂ÑÏÑùÌïòÍ≥† Excel Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
"""

import os
import re
import json
import sys
from collections import Counter, defaultdict
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor, execute_batch
from dotenv import load_dotenv
from io import StringIO

# ÏÉàÎ°ú Î∂ÑÎ¶¨Îêú Î™®Îìà import
from normalization_patterns import (
    timeframe_patterns,
    measure_patterns,
    description_patterns,
    get_sql_parseable_conditions
)
from diagnosis_queries import (
    set_excel_data,
    analyze_timeframe_patterns
)

load_dotenv()

DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'clinicaltrials'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', '')
}

# Excel Î¶¨Ìè¨Ìä∏Î•º ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
excel_data = {
    'summary': {},
    'null_analysis': [],
    'timeframe_patterns': [],
    'measure_patterns': [],
    'description_patterns': [],
    'sponsor_analysis': [],
    'official_analysis': [],
    'sponsor_class_analysis': [],
    'failure_rates': [],
    'party_overview': {},
    'sponsor_parseability': [],
    'official_parseability': []
}


def get_db_connection():
    """PostgreSQL Ïó∞Í≤∞ ÏÉùÏÑ±"""
    return psycopg2.connect(**DB_CONFIG)


def analyze_null_values(conn):
    """NULL/Îπà Í∞í Î∂ÑÏÑù (Study Îã®ÏúÑ)"""
    print("=" * 80)
    print("1. NULL/Îπà Í∞í Î∂ÑÏÑù (Study Îã®ÏúÑ)")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Ï†ÑÏ≤¥ Study Ïàò
        cur.execute("SELECT COUNT(DISTINCT nct_id) as total_studies FROM outcome_raw")
        total_studies = cur.fetchone()['total_studies']
        
        # Study Îã®ÏúÑÎ°ú Í≤∞Ï∏°Î•† Î∂ÑÏÑù (Î™®Îì† outcomeÏù¥ NULLÏù¥Î©¥ Ï∂îÏ∂ú Î∂àÍ∞ÄÎä• = Í≤∞Ï∏°)
        cur.execute("""
            WITH study_null_check AS (
                SELECT 
                    nct_id,
                    COUNT(*) as total_outcomes,
                    COUNT(CASE WHEN measure_raw IS NOT NULL AND measure_raw != '' THEN 1 END) as valid_measure_count,
                    COUNT(CASE WHEN description_raw IS NOT NULL AND description_raw != '' THEN 1 END) as valid_description_count,
                    COUNT(CASE WHEN time_frame_raw IS NOT NULL AND time_frame_raw != '' THEN 1 END) as valid_timeframe_count
                FROM outcome_raw
                GROUP BY nct_id
            )
            SELECT 
                COUNT(*) as total_studies,
                COUNT(CASE WHEN valid_measure_count = 0 THEN 1 END) as studies_with_null_measure,
                COUNT(CASE WHEN valid_description_count = 0 THEN 1 END) as studies_with_null_description,
                COUNT(CASE WHEN valid_timeframe_count = 0 THEN 1 END) as studies_with_null_timeframe
            FROM study_null_check
        """)
        stats = cur.fetchone()
        
        total = stats['total_studies']
        null_measure_studies = stats['studies_with_null_measure']
        null_description_studies = stats['studies_with_null_description']
        null_timeframe_studies = stats['studies_with_null_timeframe']
        
        print(f"\nüìä Ï†ÑÏ≤¥ Studies: {total:,}Í±¥")
        print(f"  ‚ùå measure_raw Í≤∞Ï∏° Study: {null_measure_studies:,}Í±¥ ({null_measure_studies/total*100:.1f}%)")
        print(f"  ‚ùå description_raw Í≤∞Ï∏° Study: {null_description_studies:,}Í±¥ ({null_description_studies/total*100:.1f}%)")
        print(f"  ‚ùå time_frame_raw Í≤∞Ï∏° Study: {null_timeframe_studies:,}Í±¥ ({null_timeframe_studies/total*100:.1f}%)")
        
        # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ Study Ïàò
        valid_measure_studies = total - null_measure_studies
        valid_description_studies = total - null_description_studies
        valid_timeframe_studies = total - null_timeframe_studies
        
        print(f"\n‚úÖ Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ Study Ïàò:")
        print(f"  ‚úì measure_raw Ïú†Ìö®: {valid_measure_studies:,}Í±¥ ({valid_measure_studies/total*100:.1f}%)")
        print(f"  ‚úì description_raw Ïú†Ìö®: {valid_description_studies:,}Í±¥ ({valid_description_studies/total*100:.1f}%)")
        print(f"  ‚úì time_frame_raw Ïú†Ìö®: {valid_timeframe_studies:,}Í±¥ ({valid_timeframe_studies/total*100:.1f}%)")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['null_analysis'] = {
            'total_studies': total,
            'studies_with_null_measure': null_measure_studies,
            'studies_with_null_measure_pct': null_measure_studies/total*100,
            'studies_with_null_description': null_description_studies,
            'studies_with_null_description_pct': null_description_studies/total*100,
            'studies_with_null_timeframe': null_timeframe_studies,
            'studies_with_null_timeframe_pct': null_timeframe_studies/total*100,
            'valid_measure_studies': valid_measure_studies,
            'valid_description_studies': valid_description_studies,
            'valid_timeframe_studies': valid_timeframe_studies
        }
        
        # PRIMARY vs SECONDARY ÎπÑÍµê (Study Îã®ÏúÑ)
        cur.execute("""
            WITH study_type_null AS (
                SELECT 
                    nct_id,
                    outcome_type,
                    COUNT(*) as total_outcomes,
                    COUNT(CASE WHEN measure_raw IS NOT NULL AND measure_raw != '' THEN 1 END) as valid_measure_count,
                    COUNT(CASE WHEN time_frame_raw IS NOT NULL AND time_frame_raw != '' THEN 1 END) as valid_timeframe_count
                FROM outcome_raw
                GROUP BY nct_id, outcome_type
            )
            SELECT 
                outcome_type,
                COUNT(DISTINCT nct_id) as study_count,
                COUNT(CASE WHEN valid_measure_count = 0 THEN 1 END) as studies_with_null_measure,
                COUNT(CASE WHEN valid_timeframe_count = 0 THEN 1 END) as studies_with_null_timeframe
            FROM study_type_null
            GROUP BY outcome_type
            ORDER BY outcome_type
        """)
        type_stats = cur.fetchall()
        
        print(f"\nüìã ÌÉÄÏûÖÎ≥Ñ ÌÜµÍ≥Ñ (Study Îã®ÏúÑ):")
        for row in type_stats:
            study_count = row['study_count']
            null_measure = row['studies_with_null_measure']
            null_timeframe = row['studies_with_null_timeframe']
            print(f"\n  {row['outcome_type']}: {study_count:,}Í±¥")
            print(f"    ‚ùå measure Í≤∞Ï∏° Study: {null_measure:,}Í±¥ ({null_measure/study_count*100:.1f}%)")
            print(f"    ‚ùå timeFrame Í≤∞Ï∏° Study: {null_timeframe:,}Í±¥ ({null_timeframe/study_count*100:.1f}%)")


# analyze_timeframe_patterns Ìï®ÏàòÎäî diagnosis_queries Î™®ÎìàÎ°ú Ïù¥ÎèôÎê®


def analyze_measure_patterns(conn):
    """measure Ìå®ÌÑ¥ Î∂ÑÏÑù (outcome Îã®ÏúÑ)"""
    print("\n" + "=" * 80)
    print("3. measure Ìå®ÌÑ¥ Î∂ÑÏÑù (Outcome Îã®ÏúÑ)")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # measure Í∏∏Ïù¥ Î∂ÑÏÑù
        cur.execute("""
            SELECT 
                AVG(LENGTH(measure_raw)) as avg_length,
                MIN(LENGTH(measure_raw)) as min_length,
                MAX(LENGTH(measure_raw)) as max_length,
                COUNT(*) as total
            FROM outcome_raw
            WHERE measure_raw IS NOT NULL AND measure_raw != ''
        """)
        length_stats = cur.fetchone()
        
        print(f"\nüìè measure_raw Í∏∏Ïù¥ ÌÜµÍ≥Ñ:")
        print(f"  ÌèâÍ∑†: {length_stats['avg_length']:.1f}Ïûê")
        print(f"  ÏµúÏÜå: {length_stats['min_length']}Ïûê")
        print(f"  ÏµúÎåÄ: {length_stats['max_length']}Ïûê")
        
        # Í¥ÑÌò∏ Ïïà ÏïΩÏñ¥ Ìè¨Ìï® Ïó¨Î∂Ä
        cur.execute("""
            SELECT 
                COUNT(*) as total,
                COUNT(CASE WHEN measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)' THEN 1 END) as has_abbreviation
            FROM outcome_raw
            WHERE measure_raw IS NOT NULL AND measure_raw != ''
        """)
        abbrev_stats = cur.fetchone()
        
        abbrev_pct = abbrev_stats['has_abbreviation'] / abbrev_stats['total'] * 100 if abbrev_stats['total'] > 0 else 0
        print(f"\nüî§ ÏïΩÏñ¥ ÏÇ¨Ïö© Î∂ÑÏÑù (Outcome Îã®ÏúÑ):")
        print(f"  ‚úÖ Í¥ÑÌò∏ Ïïà ÏïΩÏñ¥ Ìè¨Ìï®: {abbrev_stats['has_abbreviation']:,}Í±¥ ({abbrev_pct:.1f}%)")
        print(f"  ‚ùå ÏïΩÏñ¥ ÏóÜÏùå: {abbrev_stats['total'] - abbrev_stats['has_abbreviation']:,}Í±¥ ({(100-abbrev_pct):.1f}%)")
        
        # Top 20 measure (ÎπàÎèÑÏàú)
        cur.execute("""
            SELECT measure_raw, COUNT(*) as count
            FROM outcome_raw
            WHERE measure_raw IS NOT NULL AND measure_raw != ''
            GROUP BY measure_raw
            ORDER BY count DESC
            LIMIT 20
        """)
        top_measures = cur.fetchall()
        
        print(f"\nüèÜ ÏÉÅÏúÑ 20Í∞ú measure (ÎπàÎèÑÏàú):")
        for i, row in enumerate(top_measures, 1):
            measure = row['measure_raw'][:70] + "..." if len(row['measure_raw']) > 70 else row['measure_raw']
            print(f"  {i:2d}. [{row['count']:4d}Í±¥] {measure}")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['measure_patterns'] = [
            {
                'rank': i+1,
                'measure': row['measure_raw'],
                'count': row['count']
            }
            for i, row in enumerate(top_measures)
        ]
        excel_data['summary']['measure_avg_length'] = length_stats['avg_length']
        excel_data['summary']['measure_has_abbreviation'] = abbrev_stats['has_abbreviation']
        excel_data['summary']['measure_total'] = abbrev_stats['total']


def analyze_measure_by_study(conn):
    """measure ÏïΩÏñ¥ Ï∂îÏ∂ú - Study Îã®ÏúÑ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("üìä measure ÏïΩÏñ¥ Ï∂îÏ∂ú - Study Îã®ÏúÑ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Study Îã®ÏúÑÎ°ú ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ Ïó¨Î∂Ä Î∂ÑÏÑù
        cur.execute("""
            WITH study_abbrev AS (
                SELECT 
                    nct_id,
                    MAX(CASE WHEN outcome_type = 'PRIMARY' 
                             AND measure_raw IS NOT NULL 
                             AND measure_raw != ''
                             AND measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)' 
                        THEN 1 ELSE 0 END) as primary_has_abbrev,
                    MAX(CASE WHEN outcome_type = 'SECONDARY' 
                             AND measure_raw IS NOT NULL 
                             AND measure_raw != ''
                             AND measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)' 
                        THEN 1 ELSE 0 END) as secondary_has_abbrev,
                    MAX(CASE WHEN outcome_type = 'PRIMARY' THEN 1 ELSE 0 END) as has_primary,
                    MAX(CASE WHEN outcome_type = 'SECONDARY' THEN 1 ELSE 0 END) as has_secondary
                FROM outcome_raw
                GROUP BY nct_id
            )
            SELECT 
                COUNT(*) as total_studies,
                COUNT(CASE WHEN has_primary = 1 THEN 1 END) as studies_with_primary,
                COUNT(CASE WHEN has_secondary = 1 THEN 1 END) as studies_with_secondary,
                COUNT(CASE WHEN primary_has_abbrev = 1 THEN 1 END) as primary_success,
                COUNT(CASE WHEN secondary_has_abbrev = 1 THEN 1 END) as secondary_success,
                COUNT(CASE WHEN primary_has_abbrev = 1 AND secondary_has_abbrev = 1 THEN 1 END) as both_success,
                COUNT(CASE WHEN primary_has_abbrev = 1 AND secondary_has_abbrev = 0 THEN 1 END) as primary_only,
                COUNT(CASE WHEN primary_has_abbrev = 0 AND secondary_has_abbrev = 1 THEN 1 END) as secondary_only
            FROM study_abbrev
        """)
        
        stats = cur.fetchone()
        total = stats['total_studies']
        studies_with_primary = stats['studies_with_primary']
        studies_with_secondary = stats['studies_with_secondary']
        primary_success = stats['primary_success']
        secondary_success = stats['secondary_success']
        both_success = stats['both_success']
        primary_only = stats['primary_only']
        secondary_only = stats['secondary_only']
        
        print(f"\nüìã Ï†ÑÏ≤¥ Study Ïàò: {total:,}Í±¥")
        print(f"  ‚Ä¢ Primary outcome ÏûàÎäî Study: {studies_with_primary:,}Í±¥")
        print(f"  ‚Ä¢ Secondary outcome ÏûàÎäî Study: {studies_with_secondary:,}Í±¥")
        
        print(f"\n‚úÖ ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÎ•† (Ìï¥Îãπ outcomeÏù¥ ÏûàÎäî Study Í∏∞Ï§Ä):")
        if studies_with_primary > 0:
            primary_pct = primary_success / studies_with_primary * 100
            print(f"  üìå PRIMARY: {primary_success:,}Í±¥ / {studies_with_primary:,}Í±¥ ({primary_pct:.1f}%)")
            print(f"     ‚Üí PRIMARY outcomeÏù¥ ÏûàÎäî {studies_with_primary:,}Í±¥ Ï§ë {primary_success:,}Í±¥ÏóêÏÑú ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ")
        else:
            print(f"  üìå PRIMARY: 0Í±¥ (Primary outcomeÏù¥ ÏûàÎäî Study ÏóÜÏùå)")
        
        if studies_with_secondary > 0:
            secondary_pct = secondary_success / studies_with_secondary * 100
            print(f"  üìå SECONDARY: {secondary_success:,}Í±¥ / {studies_with_secondary:,}Í±¥ ({secondary_pct:.1f}%)")
            print(f"     ‚Üí SECONDARY outcomeÏù¥ ÏûàÎäî {studies_with_secondary:,}Í±¥ Ï§ë {secondary_success:,}Í±¥ÏóêÏÑú ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ")
        else:
            print(f"  üìå SECONDARY: 0Í±¥ (Secondary outcomeÏù¥ ÏûàÎäî Study ÏóÜÏùå)")
        
        print(f"\nüéØ ÏÉÅÏÑ∏ Î∂ÑÎ•ò (Ï†ÑÏ≤¥ {total:,}Í±¥ Study Í∏∞Ï§Ä):")
        print(f"  ‚úÖ Îëò Îã§ ÏÑ±Í≥µ: {both_success:,}Í±¥ ({both_success/total*100:.1f}%)")
        print(f"     ‚Üí PRIMARY ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ + SECONDARY ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ")
        print(f"  üìå PRIMARYÎßå ÏÑ±Í≥µ: {primary_only:,}Í±¥ ({primary_only/total*100:.1f}%)")
        print(f"     ‚Üí PRIMARY ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ + SECONDARY ÏïΩÏñ¥ Ï∂îÏ∂ú Ïã§Ìå®")
        print(f"  üìå SECONDARYÎßå ÏÑ±Í≥µ: {secondary_only:,}Í±¥ ({secondary_only/total*100:.1f}%)")
        print(f"     ‚Üí PRIMARY ÏïΩÏñ¥ Ï∂îÏ∂ú Ïã§Ìå® + SECONDARY ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ")
        both_failed = total - both_success - primary_only - secondary_only
        print(f"  ‚ùå Îëò Îã§ Ïã§Ìå®: {both_failed:,}Í±¥ ({both_failed/total*100:.1f}%)")
        print(f"     ‚Üí PRIMARY ÏïΩÏñ¥ Ï∂îÏ∂ú Ïã§Ìå® + SECONDARY ÏïΩÏñ¥ Ï∂îÏ∂ú Ïã§Ìå®")
        print(f"\n  ‚Üí Í≤ÄÏ¶ù: {both_success:,} + {primary_only:,} + {secondary_only:,} + {both_failed:,} = {total:,}Í±¥")
        print(f"  ‚Üí Í≤ÄÏ¶ù: PRIMARY ÏÑ±Í≥µ = {both_success:,} + {primary_only:,} = {primary_success:,}Í±¥ ‚úì")
        print(f"  ‚Üí Í≤ÄÏ¶ù: SECONDARY ÏÑ±Í≥µ = {both_success:,} + {secondary_only:,} = {secondary_success:,}Í±¥ ‚úì")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['measure_by_study'] = {
            'total_studies': total,
            'studies_with_primary': studies_with_primary,
            'studies_with_secondary': studies_with_secondary,
            'primary_success': primary_success,
            'primary_success_pct': primary_success / studies_with_primary * 100 if studies_with_primary > 0 else 0,
            'secondary_success': secondary_success,
            'secondary_success_pct': secondary_success / studies_with_secondary * 100 if studies_with_secondary > 0 else 0,
            'both_success': both_success,
            'both_success_pct': both_success / total * 100,
            'primary_only': primary_only,
            'secondary_only': secondary_only,
            'both_failed': total - both_success - primary_only - secondary_only
        }


def analyze_timeframe_by_study(conn):
    """timeFrame ÌååÏã± - Study Îã®ÏúÑ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("üìä timeFrame ÌååÏã± - Study Îã®ÏúÑ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Study Îã®ÏúÑÎ°ú timeFrame ÌååÏã± ÏÑ±Í≥µ Ïó¨Î∂Ä Î∂ÑÏÑù
        # outcome ÏÑ±Í≥µ = measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ (Í¥ÑÌò∏ Ïïà ÏïΩÏñ¥ Ìè¨Ìï®)
        cur.execute("""
            WITH study_timeframe AS (
                SELECT 
                    nct_id,
                    -- PRIMARY outcome Ï°¥Ïû¨ Ïó¨Î∂Ä
                    MAX(CASE WHEN outcome_type = 'PRIMARY' THEN 1 ELSE 0 END) as has_primary_outcome,
                    -- SECONDARY outcome Ï°¥Ïû¨ Ïó¨Î∂Ä
                    MAX(CASE WHEN outcome_type = 'SECONDARY' THEN 1 ELSE 0 END) as has_secondary_outcome,
                    -- PRIMARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ Ïó¨Î∂Ä
                    MAX(CASE WHEN outcome_type = 'PRIMARY' 
                             AND measure_raw IS NOT NULL 
                             AND measure_raw != ''
                             AND measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)'
                        THEN 1 ELSE 0 END) as has_primary_measure,
                    -- SECONDARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ Ïó¨Î∂Ä
                    MAX(CASE WHEN outcome_type = 'SECONDARY' 
                             AND measure_raw IS NOT NULL 
                             AND measure_raw != ''
                             AND measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)'
                        THEN 1 ELSE 0 END) as has_secondary_measure,
                    -- PRIMARY outcomeÏùò timeFrame ÌååÏã± ÏÑ±Í≥µ Ïó¨Î∂Ä
                    MAX(CASE WHEN outcome_type = 'PRIMARY' 
                             AND time_frame_raw IS NOT NULL 
                             AND time_frame_raw != ''
                             AND (
                                 time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)'
                                 OR time_frame_raw ~* '\\bat\\s+(day|days|week|weeks|month|months)\\s+\\d+'
                                 OR time_frame_raw ~* '\\b(day|days|month|months|week|weeks)\\s+\\d+'
                                 OR time_frame_raw ~* '\\bday\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+'
                                 OR time_frame_raw ~* '\\bfor\\s+\\d+\\s+(month|months|week|weeks|day|days)'
                                 OR time_frame_raw ~* '\\bat\\s+months?\\s+\\d+\\s+and\\s+\\d+'
                                 OR time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)'
                                 OR time_frame_raw ~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)'
                                 OR time_frame_raw ~* 'year\\s*\\d+'
                                 OR time_frame_raw ~* 'up\\s+to\\s+\\d+'
                                 OR time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)'
                             )
                        THEN 1 ELSE 0 END) as primary_timeframe_success,
                    -- SECONDARY outcomeÏùò timeFrame ÌååÏã± ÏÑ±Í≥µ Ïó¨Î∂Ä
                    MAX(CASE WHEN outcome_type = 'SECONDARY' 
                             AND time_frame_raw IS NOT NULL 
                             AND time_frame_raw != ''
                             AND (
                                 time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)'
                                 OR time_frame_raw ~* '\\bat\\s+(day|days|week|weeks|month|months)\\s+\\d+'
                                 OR time_frame_raw ~* '\\b(day|days|month|months|week|weeks)\\s+\\d+'
                                 OR time_frame_raw ~* '\\bday\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+'
                                 OR time_frame_raw ~* '\\bfor\\s+\\d+\\s+(month|months|week|weeks|day|days)'
                                 OR time_frame_raw ~* '\\bat\\s+months?\\s+\\d+\\s+and\\s+\\d+'
                                 OR time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)'
                                 OR time_frame_raw ~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)'
                                 OR time_frame_raw ~* 'year\\s*\\d+'
                                 OR time_frame_raw ~* 'up\\s+to\\s+\\d+'
                                 OR time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)'
                             )
                        THEN 1 ELSE 0 END) as secondary_timeframe_success
                FROM outcome_raw
                GROUP BY nct_id
            )
            SELECT 
                COUNT(*) as total_studies,
                -- PRIMARY outcomeÏù¥ ÏûàÎäî Study Ïàò (measure ÏÑ±Í≥µ Ïó¨Î∂ÄÏôÄ Î¨¥Í¥Ä)
                COUNT(CASE WHEN has_primary_outcome = 1 THEN 1 END) as studies_with_primary_outcome,
                -- SECONDARY outcomeÏù¥ ÏûàÎäî Study Ïàò (measure ÏÑ±Í≥µ Ïó¨Î∂ÄÏôÄ Î¨¥Í¥Ä)
                COUNT(CASE WHEN has_secondary_outcome = 1 THEN 1 END) as studies_with_secondary_outcome,
                -- PRIMARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÌïú Study Ïàò
                COUNT(CASE WHEN has_primary_measure = 1 THEN 1 END) as studies_with_primary_measure,
                -- SECONDARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÌïú Study Ïàò
                COUNT(CASE WHEN has_secondary_measure = 1 THEN 1 END) as studies_with_secondary_measure,
                -- PRIMARY: measure ÏÑ±Í≥µ + timeFrame ÏÑ±Í≥µ
                COUNT(CASE WHEN has_primary_measure = 1 AND primary_timeframe_success = 1 THEN 1 END) as outcome_frame_both_primary,
                -- SECONDARY: measure ÏÑ±Í≥µ + timeFrame ÏÑ±Í≥µ
                COUNT(CASE WHEN has_secondary_measure = 1 AND secondary_timeframe_success = 1 THEN 1 END) as outcome_frame_both_secondary,
                -- PRIMARY: measure ÏÑ±Í≥µ + timeFrame Ïã§Ìå®
                COUNT(CASE WHEN has_primary_measure = 1 AND primary_timeframe_success = 0 THEN 1 END) as outcome_only_primary,
                -- SECONDARY: measure ÏÑ±Í≥µ + timeFrame Ïã§Ìå®
                COUNT(CASE WHEN has_secondary_measure = 1 AND secondary_timeframe_success = 0 THEN 1 END) as outcome_only_secondary,
                -- PRIMARY: measure Ïã§Ìå® + timeFrame ÏÑ±Í≥µ (PRIMARY outcomeÏù¥ ÏûàÎäî Study Ï§ëÏóêÏÑúÎßå)
                COUNT(CASE WHEN has_primary_outcome = 1 AND has_primary_measure = 0 AND primary_timeframe_success = 1 THEN 1 END) as frame_only_primary,
                -- SECONDARY: measure Ïã§Ìå® + timeFrame ÏÑ±Í≥µ (SECONDARY outcomeÏù¥ ÏûàÎäî Study Ï§ëÏóêÏÑúÎßå)
                COUNT(CASE WHEN has_secondary_outcome = 1 AND has_secondary_measure = 0 AND secondary_timeframe_success = 1 THEN 1 END) as frame_only_secondary
            FROM study_timeframe
        """)
        
        stats = cur.fetchone()
        total = stats['total_studies']
        studies_with_primary_outcome = stats['studies_with_primary_outcome']
        studies_with_secondary_outcome = stats['studies_with_secondary_outcome']
        studies_with_primary_measure = stats['studies_with_primary_measure']
        studies_with_secondary_measure = stats['studies_with_secondary_measure']
        both_primary = stats['outcome_frame_both_primary']
        both_secondary = stats['outcome_frame_both_secondary']
        outcome_only_primary = stats['outcome_only_primary']
        outcome_only_secondary = stats['outcome_only_secondary']
        frame_only_primary = stats['frame_only_primary']
        frame_only_secondary = stats['frame_only_secondary']
        
        print(f"\nüìã Ï†ÑÏ≤¥ Study Ïàò: {total:,}Í±¥")
        print(f"  ‚Ä¢ PRIMARY outcome ÏûàÎäî Study: {studies_with_primary_outcome:,}Í±¥")
        print(f"  ‚Ä¢ SECONDARY outcome ÏûàÎäî Study: {studies_with_secondary_outcome:,}Í±¥")
        print(f"  ‚Ä¢ PRIMARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ: {studies_with_primary_measure:,}Í±¥")
        print(f"  ‚Ä¢ SECONDARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µ: {studies_with_secondary_measure:,}Í±¥")
        
        print(f"\n‚úÖ PRIMARY Outcome (measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÌïú {studies_with_primary_measure:,}Í±¥ Í∏∞Ï§Ä):")
        if studies_with_primary_measure > 0:
            print(f"  ‚úÖ outcome + frame Îëò Îã§ ÏÑ±Í≥µ: {both_primary:,}Í±¥ ({both_primary/studies_with_primary_measure*100:.1f}%)")
            print(f"  üìå outcomeÎßå ÏÑ±Í≥µ (frame Ïã§Ìå®): {outcome_only_primary:,}Í±¥ ({outcome_only_primary/studies_with_primary_measure*100:.1f}%)")
            # frameÎßå ÏÑ±Í≥µÏùÄ PRIMARY outcomeÏù¥ ÏûàÎäî Study Ï§ëÏóêÏÑú measure Ïã§Ìå®ÌñàÏßÄÎßå timeFrame ÏÑ±Í≥µÌïú Í≤ΩÏö∞
            print(f"  üìå frameÎßå ÏÑ±Í≥µ (measure Ïã§Ìå®, PRIMARY outcome ÏûàÏùå): {frame_only_primary:,}Í±¥")
            if studies_with_primary_outcome > 0:
                print(f"  ‚Üí Í≤ÄÏ¶ù (measure ÏÑ±Í≥µ Í∏∞Ï§Ä): {both_primary + outcome_only_primary:,}Í±¥ = {studies_with_primary_measure:,}Í±¥")
                print(f"  ‚Üí Í≤ÄÏ¶ù (PRIMARY outcome Ï†ÑÏ≤¥ Í∏∞Ï§Ä): {both_primary + outcome_only_primary + frame_only_primary:,}Í±¥ ‚â§ {studies_with_primary_outcome:,}Í±¥")
        else:
            print(f"  PRIMARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÌïú Study ÏóÜÏùå")
        
        print(f"\n‚úÖ SECONDARY Outcome (measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÌïú {studies_with_secondary_measure:,}Í±¥ Í∏∞Ï§Ä):")
        if studies_with_secondary_measure > 0:
            print(f"  ‚úÖ outcome + frame Îëò Îã§ ÏÑ±Í≥µ: {both_secondary:,}Í±¥ ({both_secondary/studies_with_secondary_measure*100:.1f}%)")
            print(f"  üìå outcomeÎßå ÏÑ±Í≥µ (frame Ïã§Ìå®): {outcome_only_secondary:,}Í±¥ ({outcome_only_secondary/studies_with_secondary_measure*100:.1f}%)")
            # frameÎßå ÏÑ±Í≥µÏùÄ SECONDARY outcomeÏù¥ ÏûàÎäî Study Ï§ëÏóêÏÑú measure Ïã§Ìå®ÌñàÏßÄÎßå timeFrame ÏÑ±Í≥µÌïú Í≤ΩÏö∞
            print(f"  üìå frameÎßå ÏÑ±Í≥µ (measure Ïã§Ìå®, SECONDARY outcome ÏûàÏùå): {frame_only_secondary:,}Í±¥")
            if studies_with_secondary_outcome > 0:
                print(f"  ‚Üí Í≤ÄÏ¶ù (measure ÏÑ±Í≥µ Í∏∞Ï§Ä): {both_secondary + outcome_only_secondary:,}Í±¥ = {studies_with_secondary_measure:,}Í±¥")
                print(f"  ‚Üí Í≤ÄÏ¶ù (SECONDARY outcome Ï†ÑÏ≤¥ Í∏∞Ï§Ä): {both_secondary + outcome_only_secondary + frame_only_secondary:,}Í±¥ ‚â§ {studies_with_secondary_outcome:,}Í±¥")
        else:
            print(f"  SECONDARY outcomeÏùò measure ÏïΩÏñ¥ Ï∂îÏ∂ú ÏÑ±Í≥µÌïú Study ÏóÜÏùå")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['timeframe_by_study'] = {
            'total_studies': total,
            'primary_both_success': both_primary,
            'primary_both_success_pct': both_primary / total * 100,
            'primary_outcome_only': outcome_only_primary,
            'primary_frame_only': frame_only_primary,
            'secondary_both_success': both_secondary,
            'secondary_both_success_pct': both_secondary / total * 100,
            'secondary_outcome_only': outcome_only_secondary,
            'secondary_frame_only': frame_only_secondary
        }


def analyze_description_patterns(conn):
    """description Ìå®ÌÑ¥ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("4. description Ìå®ÌÑ¥ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # change from baseline Ìå®ÌÑ¥
        cur.execute("""
            SELECT 
                COUNT(*) as total,
                COUNT(CASE WHEN description_raw ~* 'change.*from.*baseline|difference.*from.*baseline' THEN 1 END) as has_change_from_baseline
            FROM outcome_raw
            WHERE description_raw IS NOT NULL AND description_raw != ''
        """)
        baseline_stats = cur.fetchone()
        
        baseline_pct = baseline_stats['has_change_from_baseline'] / baseline_stats['total'] * 100 if baseline_stats['total'] > 0 else 0
        print(f"\nüìä 'change from baseline' Ìå®ÌÑ¥ Î∂ÑÏÑù:")
        print(f"  ‚úÖ Î∞úÍ≤¨: {baseline_stats['has_change_from_baseline']:,}Í±¥ ({baseline_pct:.1f}%)")
        print(f"  ‚ùå ÎØ∏Î∞úÍ≤¨: {baseline_stats['total'] - baseline_stats['has_change_from_baseline']:,}Í±¥ ({(100-baseline_pct):.1f}%)")
        print(f"  üìã Ï†ÑÏ≤¥: {baseline_stats['total']:,}Í±¥")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['description_patterns'] = {
            'total': baseline_stats['total'],
            'has_change_from_baseline': baseline_stats['has_change_from_baseline'],
            'no_change_from_baseline': baseline_stats['total'] - baseline_stats['has_change_from_baseline']
        }


def analyze_party_overview(conn):
    """Í∏∞Í¥Ä/Îã¥ÎãπÏûê Ï†ÑÏ≤¥ ÌÜµÍ≥Ñ"""
    print("\n" + "=" * 80)
    print("üìä Í∏∞Í¥Ä/Îã¥ÎãπÏûê Ï†ÑÏ≤¥ ÌÜµÍ≥Ñ")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # LEAD_SPONSOR ÌÜµÍ≥Ñ
        cur.execute("""
            SELECT 
                COUNT(DISTINCT name_raw) as total_sponsors,
                COUNT(DISTINCT nct_id) as total_studies,
                COUNT(*) as total_records
            FROM study_party_raw
            WHERE party_type = 'LEAD_SPONSOR'
        """)
        sponsor_stats = cur.fetchone()
        
        # OFFICIAL ÌÜµÍ≥Ñ
        cur.execute("""
            SELECT 
                COUNT(DISTINCT name_raw) as total_officials,
                COUNT(DISTINCT nct_id) as total_studies,
                COUNT(*) as total_records
            FROM study_party_raw
            WHERE party_type = 'OFFICIAL'
        """)
        official_stats = cur.fetchone()
        
        # Í∏∞Í¥ÄÎ≥Ñ study Î∂ÑÌè¨
        cur.execute("""
            SELECT 
                COUNT(*) as sponsor_count,
                AVG(study_count) as avg_studies,
                MIN(study_count) as min_studies,
                MAX(study_count) as max_studies
            FROM (
                SELECT 
                    name_raw,
                    COUNT(DISTINCT nct_id) as study_count
                FROM study_party_raw
                WHERE party_type = 'LEAD_SPONSOR'
                GROUP BY name_raw
            ) sub
        """)
        sponsor_dist = cur.fetchone()
        
        # Îã¥ÎãπÏûêÎ≥Ñ study Î∂ÑÌè¨
        cur.execute("""
            SELECT 
                COUNT(*) as official_count,
                AVG(study_count) as avg_studies,
                MIN(study_count) as min_studies,
                MAX(study_count) as max_studies
            FROM (
                SELECT 
                    name_raw,
                    COUNT(DISTINCT nct_id) as study_count
                FROM study_party_raw
                WHERE party_type = 'OFFICIAL'
                GROUP BY name_raw
            ) sub
        """)
        official_dist = cur.fetchone()
        
        print(f"\nüè¢ LEAD_SPONSOR (Í∏∞Í¥Ä) ÌÜµÍ≥Ñ:")
        print(f"  Ï¥ù Í∏∞Í¥Ä Ïàò: {sponsor_stats['total_sponsors']:,}Í∞ú")
        print(f"  Ï¥ù Study Ïàò: {sponsor_stats['total_studies']:,}Í±¥")
        print(f"  Ï¥ù Î†àÏΩîÎìú Ïàò: {sponsor_stats['total_records']:,}Í±¥")
        print(f"\n  Study Î∂ÑÌè¨:")
        print(f"    ÌèâÍ∑†: {sponsor_dist['avg_studies']:.1f}Í±¥/Í∏∞Í¥Ä")
        print(f"    ÏµúÏÜå: {sponsor_dist['min_studies']:,}Í±¥")
        print(f"    ÏµúÎåÄ: {sponsor_dist['max_studies']:,}Í±¥")
        
        print(f"\nüë§ OFFICIAL (Îã¥ÎãπÏûê) ÌÜµÍ≥Ñ:")
        print(f"  Ï¥ù Îã¥ÎãπÏûê Ïàò: {official_stats['total_officials']:,}Î™Ö")
        print(f"  Ï¥ù Study Ïàò: {official_stats['total_studies']:,}Í±¥")
        print(f"  Ï¥ù Î†àÏΩîÎìú Ïàò: {official_stats['total_records']:,}Í±¥")
        print(f"\n  Study Î∂ÑÌè¨:")
        print(f"    ÌèâÍ∑†: {official_dist['avg_studies']:.1f}Í±¥/Îã¥ÎãπÏûê")
        print(f"    ÏµúÏÜå: {official_dist['min_studies']:,}Í±¥")
        print(f"    ÏµúÎåÄ: {official_dist['max_studies']:,}Í±¥")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['party_overview'] = {
            'total_sponsors': sponsor_stats['total_sponsors'],
            'total_sponsor_studies': sponsor_stats['total_studies'],
            'total_sponsor_records': sponsor_stats['total_records'],
            'sponsor_avg_studies': float(sponsor_dist['avg_studies']),
            'sponsor_min_studies': sponsor_dist['min_studies'],
            'sponsor_max_studies': sponsor_dist['max_studies'],
            'total_officials': official_stats['total_officials'],
            'total_official_studies': official_stats['total_studies'],
            'total_official_records': official_stats['total_records'],
            'official_avg_studies': float(official_dist['avg_studies']),
            'official_min_studies': official_dist['min_studies'],
            'official_max_studies': official_dist['max_studies']
        }


def analyze_by_lead_sponsor(conn):
    """LEAD_SPONSORÎ≥Ñ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("5. LEAD_SPONSORÎ≥Ñ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # LEAD_SPONSORÎ≥Ñ ÌÜµÍ≥Ñ (ÌååÏã± Í∞ÄÎä•ÏÑ± Ìè¨Ìï®)
        cur.execute("""
            SELECT 
                sp.name_raw as sponsor_name,
                sp.class_raw as sponsor_class,
                COUNT(DISTINCT o.nct_id) as study_count,
                COUNT(*) as outcome_count,
                COUNT(CASE WHEN o.outcome_type = 'PRIMARY' THEN 1 END) as primary_count,
                COUNT(CASE WHEN o.outcome_type = 'SECONDARY' THEN 1 END) as secondary_count,
                COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END) as null_timeframe,
                COUNT(CASE WHEN o.time_frame_raw ~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)' THEN 1 END) as period_pattern,
                COUNT(CASE WHEN o.time_frame_raw ~* 'year\\s*\\d+' THEN 1 END) as year_pattern,
                COUNT(CASE WHEN o.time_frame_raw ~* 'up\\s+to\\s+\\d+' THEN 1 END) as upto_pattern,
                COUNT(CASE WHEN o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)' THEN 1 END) as through_pattern
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'LEAD_SPONSOR'
            GROUP BY sp.name_raw, sp.class_raw
            ORDER BY study_count DESC
            LIMIT 20
        """)
        
        sponsors = cur.fetchall()
        
        print(f"\nüè¢ Top 20 LEAD_SPONSOR (Studies Í∏∞Ï§Ä):")
        print(f"{'ÏàúÏúÑ':<5} {'Ïä§Ìè∞ÏÑúÎ™Ö':<40} {'ÌÅ¥ÎûòÏä§':<15} {'Studies':<10} {'Outcomes':<10} {'Parseable':<12} {'Parse%':<10}")
        print("-" * 110)
        
        for i, row in enumerate(sponsors, 1):
            sponsor_name = (row['sponsor_name'] or 'N/A')[:38]
            sponsor_class = (row['sponsor_class'] or 'N/A')[:13]
            total = row['outcome_count']
            null_count = row['null_timeframe']
            valid_count = total - null_count
            
            # ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Ìï©Í≥Ñ
            parseable = (row['period_pattern'] + row['year_pattern'] + 
                        row['upto_pattern'] + row['through_pattern'])
            parseable_pct = (parseable / valid_count * 100) if valid_count > 0 else 0
            
            print(f"{i:<5} {sponsor_name:<40} {sponsor_class:<15} {row['study_count']:<10} "
                  f"{total:<10} {parseable:<12} {parseable_pct:<9.1f}%")
            
            # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['sponsor_analysis'].append({
                'rank': i,
                'sponsor_name': row['sponsor_name'],
                'sponsor_class': row['sponsor_class'],
                'study_count': row['study_count'],
                'outcome_count': total,
                'null_timeframe': null_count,
                'parseable_count': parseable,
                'parseable_pct': parseable_pct
            })
            
            # ÌååÏã± Í∞ÄÎä•ÏÑ± ÏÉÅÏÑ∏ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['sponsor_parseability'].append({
                'rank': i,
                'sponsor_name': row['sponsor_name'],
                'sponsor_class': row['sponsor_class'],
                'study_count': row['study_count'],
                'total_outcomes': total,
                'null_count': null_count,
                'valid_count': valid_count,
                'period_pattern': row['period_pattern'],
                'year_pattern': row['year_pattern'],
                'upto_pattern': row['upto_pattern'],
                'through_pattern': row['through_pattern'],
                'parseable_count': parseable,
                'parseable_pct': parseable_pct,
                'unparseable_count': valid_count - parseable,
                'unparseable_pct': ((valid_count - parseable) / valid_count * 100) if valid_count > 0 else 0
            })
        
        # LEAD_SPONSORÎ≥Ñ timeFrame Ìå®ÌÑ¥ Î∂ÑÏÑù (Ïö∞ÏÑ†ÏàúÏúÑ Ï†ÅÏö©ÌïòÏó¨ Ï§ëÎ≥µ Ï†úÍ±∞)
        print("\n" + "-" * 80)
        print("LEAD_SPONSORÎ≥Ñ timeFrame Ìå®ÌÑ¥ (Top 10)")
        print("-" * 80)
        
        cur.execute("""
            WITH sponsor_timeframe_patterns AS (
                SELECT 
                    sp.name_raw as sponsor_name,
                    o.time_frame_raw,
                    CASE 
                        WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 'null'
                        WHEN o.time_frame_raw ~* 'year\\s*\\d+' THEN 'year'
                        WHEN o.time_frame_raw ~* 'up\\s+to\\s+\\d+' THEN 'upto'
                        WHEN o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)' THEN 'through'
                        WHEN o.time_frame_raw ~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)' THEN 'period'
                        ELSE 'unparseable'
                    END as pattern_type
                FROM outcome_raw o
                INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
                WHERE sp.party_type = 'LEAD_SPONSOR'
            )
            SELECT 
                sponsor_name,
                COUNT(*) as total_outcomes,
                COUNT(CASE WHEN pattern_type = 'null' THEN 1 END) as null_pattern,
                COUNT(CASE WHEN pattern_type = 'year' THEN 1 END) as year_pattern,
                COUNT(CASE WHEN pattern_type = 'upto' THEN 1 END) as upto_pattern,
                COUNT(CASE WHEN pattern_type = 'through' THEN 1 END) as through_pattern,
                COUNT(CASE WHEN pattern_type = 'period' THEN 1 END) as period_pattern,
                COUNT(CASE WHEN pattern_type = 'unparseable' THEN 1 END) as unparseable_pattern
            FROM sponsor_timeframe_patterns
            GROUP BY sponsor_name
            HAVING COUNT(*) >= 10
            ORDER BY total_outcomes DESC
            LIMIT 10
        """)
        
        sponsor_patterns = cur.fetchall()
        
        for row in sponsor_patterns:
            sponsor_name = (row['sponsor_name'] or 'N/A')[:50]
            total = row['total_outcomes']
            period = row['period_pattern']
            year = row['year_pattern']
            upto = row['upto_pattern']
            through = row['through_pattern']
            null_count = row['null_pattern']
            unparseable = row['unparseable_pattern']
            
            # ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Ìï©Í≥Ñ (Ï§ëÎ≥µ Ï†úÍ±∞Îê®)
            parseable = period + year + upto + through
            
            print(f"\n  üìå {sponsor_name} (Ï¥ù {total:,}Í±¥):")
            print(f"     ‚Ä¢ Period pattern: {period:,}Í±¥ ({period/total*100:.1f}%)")
            print(f"     ‚Ä¢ Year pattern: {year:,}Í±¥ ({year/total*100:.1f}%)")
            print(f"     ‚Ä¢ Up to pattern: {upto:,}Í±¥ ({upto/total*100:.1f}%)")
            print(f"     ‚Ä¢ Through pattern: {through:,}Í±¥ ({through/total*100:.1f}%)")
            print(f"     ‚Ä¢ Null/Empty: {null_count:,}Í±¥ ({null_count/total*100:.1f}%)")
            print(f"     ‚Üí ‚úÖ ÌååÏã± Í∞ÄÎä•: {parseable:,}Í±¥ ({parseable/total*100:.1f}%)")
            print(f"     ‚Üí ‚ùå ÌååÏã± Ïñ¥Î†§ÏõÄ: {unparseable:,}Í±¥ ({unparseable/total*100:.1f}%)")


def analyze_by_official(conn):
    """OFFICIAL(Îã¥ÎãπÏûê)Î≥Ñ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("6. OFFICIAL(Îã¥ÎãπÏûê)Î≥Ñ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # OFFICIALÎ≥Ñ ÌÜµÍ≥Ñ (ÌååÏã± Í∞ÄÎä•ÏÑ± Ìè¨Ìï®)
        cur.execute("""
            SELECT 
                sp.name_raw as official_name,
                sp.affiliation_raw as affiliation,
                COUNT(DISTINCT o.nct_id) as study_count,
                COUNT(*) as outcome_count,
                COUNT(CASE WHEN o.outcome_type = 'PRIMARY' THEN 1 END) as primary_count,
                COUNT(CASE WHEN o.outcome_type = 'SECONDARY' THEN 1 END) as secondary_count,
                COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END) as null_timeframe,
                COUNT(CASE WHEN o.time_frame_raw ~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)' THEN 1 END) as period_pattern,
                COUNT(CASE WHEN o.time_frame_raw ~* 'year\\s*\\d+' THEN 1 END) as year_pattern,
                COUNT(CASE WHEN o.time_frame_raw ~* 'up\\s+to\\s+\\d+' THEN 1 END) as upto_pattern,
                COUNT(CASE WHEN o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)' THEN 1 END) as through_pattern
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'OFFICIAL'
            GROUP BY sp.name_raw, sp.affiliation_raw
            ORDER BY study_count DESC
            LIMIT 20
        """)
        
        officials = cur.fetchall()
        
        print(f"\nüë§ Top 20 OFFICIAL (Studies Í∏∞Ï§Ä):")
        print(f"{'ÏàúÏúÑ':<5} {'Îã¥ÎãπÏûêÎ™Ö':<35} {'ÏÜåÏÜç':<40} {'Studies':<10} {'Outcomes':<10} {'Parseable':<12} {'Parse%':<10}")
        print("-" * 125)
        
        for i, row in enumerate(officials, 1):
            official_name = (row['official_name'] or 'N/A')[:33]
            affiliation = (row['affiliation'] or 'N/A')[:38]
            total = row['outcome_count']
            null_count = row['null_timeframe']
            valid_count = total - null_count
            
            # ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Ìï©Í≥Ñ
            parseable = (row['period_pattern'] + row['year_pattern'] + 
                        row['upto_pattern'] + row['through_pattern'])
            parseable_pct = (parseable / valid_count * 100) if valid_count > 0 else 0
            
            print(f"{i:<5} {official_name:<35} {affiliation:<40} {row['study_count']:<10} "
                  f"{total:<10} {parseable:<12} {parseable_pct:<9.1f}%")
            
            # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['official_analysis'].append({
                'rank': i,
                'official_name': row['official_name'],
                'affiliation': row['affiliation'],
                'study_count': row['study_count'],
                'outcome_count': total,
                'null_timeframe': null_count,
                'parseable_count': parseable,
                'parseable_pct': parseable_pct
            })
            
            # ÌååÏã± Í∞ÄÎä•ÏÑ± ÏÉÅÏÑ∏ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['official_parseability'].append({
                'rank': i,
                'official_name': row['official_name'],
                'affiliation': row['affiliation'],
                'study_count': row['study_count'],
                'total_outcomes': total,
                'null_count': null_count,
                'valid_count': valid_count,
                'period_pattern': row['period_pattern'],
                'year_pattern': row['year_pattern'],
                'upto_pattern': row['upto_pattern'],
                'through_pattern': row['through_pattern'],
                'parseable_count': parseable,
                'parseable_pct': parseable_pct,
                'unparseable_count': valid_count - parseable,
                'unparseable_pct': ((valid_count - parseable) / valid_count * 100) if valid_count > 0 else 0
            })
        
        # OFFICIALÎ≥Ñ measure Ìå®ÌÑ¥ Î∂ÑÏÑù
        print("\n" + "-" * 80)
        print("OFFICIALÎ≥Ñ measure Ìå®ÌÑ¥ (Top 10)")
        print("-" * 80)
        
        cur.execute("""
            SELECT 
                sp.name_raw as official_name,
                sp.affiliation_raw as affiliation,
                COUNT(*) as total_outcomes,
                COUNT(CASE WHEN o.measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)' THEN 1 END) as has_abbreviation,
                COUNT(CASE WHEN o.description_raw ~* 'change.*from.*baseline' THEN 1 END) as change_from_baseline
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'OFFICIAL'
            GROUP BY sp.name_raw, sp.affiliation_raw
            HAVING COUNT(*) >= 10
            ORDER BY total_outcomes DESC
            LIMIT 10
        """)
        
        official_patterns = cur.fetchall()
        
        for row in official_patterns:
            official_name = (row['official_name'] or 'N/A')[:40]
            affiliation = (row['affiliation'] or 'N/A')[:40]
            total = row['total_outcomes']
            has_abbrev = row['has_abbreviation']
            has_baseline = row['change_from_baseline']
            
            print(f"\n  üìå {official_name} ({affiliation}) - Ï¥ù {total:,}Í±¥:")
            print(f"     ‚Ä¢ ÏïΩÏñ¥ Ìè¨Ìï®: {has_abbrev:,}Í±¥ ({has_abbrev/total*100:.1f}%)")
            print(f"     ‚Ä¢ Change from baseline: {has_baseline:,}Í±¥ ({has_baseline/total*100:.1f}%)")


def analyze_sponsor_class_patterns(conn):
    """Sponsor ClassÎ≥Ñ Ìå®ÌÑ¥ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("7. Sponsor ClassÎ≥Ñ Ìå®ÌÑ¥ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        cur.execute("""
            SELECT 
                sp.class_raw as sponsor_class,
                COUNT(DISTINCT o.nct_id) as study_count,
                COUNT(*) as outcome_count,
                COUNT(CASE WHEN o.time_frame_raw ~ '\\d+\\s*(week|weeks|month|months|year|years)' THEN 1 END) as period_pattern_count,
                COUNT(CASE WHEN o.measure_raw ~ '\\([A-Z][A-Z0-9\\-+\\s]+\\)' THEN 1 END) as abbreviation_count,
                AVG(LENGTH(o.measure_raw)) as avg_measure_length
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'LEAD_SPONSOR'
                AND sp.class_raw IS NOT NULL
            GROUP BY sp.class_raw
            ORDER BY study_count DESC
        """)
        
        classes = cur.fetchall()
        
        print(f"\nüìä Sponsor ClassÎ≥Ñ ÌÜµÍ≥Ñ:")
        print(f"{'Class':<20} {'Studies':<12} {'Outcomes':<12} {'Period Pattern':<30} {'Abbrev':<30} {'Avg Length':<12}")
        print("-" * 120)
        
        for row in classes:
            sponsor_class = (row['sponsor_class'] or 'N/A')[:18]
            total = row['outcome_count']
            period_count = row['period_pattern_count']
            abbrev_count = row['abbreviation_count']
            period_pct = (period_count / total * 100) if total > 0 else 0
            abbrev_pct = (abbrev_count / total * 100) if total > 0 else 0
            avg_length = row['avg_measure_length'] or 0
            
            print(f"{sponsor_class:<20} {row['study_count']:<12} {total:<12} "
                  f"{period_count:,}Í±¥({period_pct:.1f}%) {abbrev_count:,}Í±¥({abbrev_pct:.1f}%) {avg_length:<11.1f}")
            
            # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['sponsor_class_analysis'].append({
                'sponsor_class': row['sponsor_class'],
                'study_count': row['study_count'],
                'outcome_count': total,
                'period_pattern_count': period_count,
                'period_pattern_pct': period_pct,
                'abbreviation_count': abbrev_count,
                'abbreviation_pct': abbrev_pct,
                'avg_measure_length': float(avg_length) if avg_length else 0
            })


def analyze_failure_rates_by_party(conn):
    """Í∏∞Í¥Ä/Îã¥ÎãπÏûêÎ≥Ñ Îß§Ìïë Ïã§Ìå®Ïú® Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("8. Í∏∞Í¥Ä/Îã¥ÎãπÏûêÎ≥Ñ ÏòàÏÉÅ Îß§Ìïë Ïã§Ìå®Ïú® Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # LEAD_SPONSORÎ≥Ñ
        print("\n[LEAD_SPONSORÎ≥Ñ - ÏòàÏÉÅ timeFrame ÌååÏã± Ïã§Ìå®Ïú®]")
        cur.execute("""
            SELECT 
                sp.name_raw as sponsor_name,
                COUNT(*) as total,
                COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END) as null_count,
                COUNT(CASE WHEN o.time_frame_raw !~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)' 
                          AND o.time_frame_raw !~* 'year\\s*\\d+'
                          AND o.time_frame_raw !~* 'up\\s+to'
                          AND o.time_frame_raw !~* 'through.*completion'
                          AND o.time_frame_raw IS NOT NULL 
                          AND o.time_frame_raw != '' THEN 1 END) as complex_pattern_count,
                CASE 
                    WHEN COUNT(*) - COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END) > 0
                    THEN (COUNT(CASE WHEN o.time_frame_raw !~ '\\d+\\s*(week|weeks|month|months|year|years|day|days|hour|hours)' 
                              AND o.time_frame_raw !~* 'year\\s*\\d+'
                              AND o.time_frame_raw !~* 'up\\s+to'
                              AND o.time_frame_raw !~* 'through.*completion'
                              AND o.time_frame_raw IS NOT NULL 
                              AND o.time_frame_raw != '' THEN 1 END)::float / 
                          NULLIF(COUNT(*) - COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END), 0) * 100)
                    ELSE 0
                END as failure_rate
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'LEAD_SPONSOR'
            GROUP BY sp.name_raw
            HAVING COUNT(*) >= 20
            ORDER BY failure_rate DESC
            LIMIT 10
        """)
        
        failure_rates = cur.fetchall()
        
        print(f"{'Ïä§Ìè∞ÏÑúÎ™Ö':<50} {'Total':<10} {'Null':<10} {'Complex':<10} {'Failure Rate':<12}")
        print("-" * 100)
        
        for row in failure_rates:
            sponsor_name = (row['sponsor_name'] or 'N/A')[:48]
            total = row['total']
            null_count = row['null_count']
            complex_count = row['complex_pattern_count']
            failure_rate = row['failure_rate'] or 0
            
            print(f"{sponsor_name:<50} {total:<10} {null_count:<10} {complex_count:<10} {failure_rate:<11.1f}%")
            
            # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['failure_rates'].append({
                'sponsor_name': row['sponsor_name'],
                'total': total,
                'null_count': null_count,
                'complex_count': complex_count,
                'failure_rate': float(failure_rate)
            })


def explain_normalization_rules():
    """Ï†ïÍ∑úÌôî Î£∞ ÏÑ§Î™Ö"""
    print("\n" + "=" * 80)
    print("üìã Ï†ïÍ∑úÌôî Î£∞ ÏÑ§Î™Ö")
    print("=" * 80)
    
    print("""
üîß 1Ï∞® Ï†ïÍ∑úÌôî Î£∞ (Phase 1):

1. ÌÖçÏä§Ìä∏ ÌÅ¥Î¶¨Îãù:
   ‚Ä¢ Í≥µÎ∞± Ï†ïÎ¶¨ (Ïó∞ÏÜç Í≥µÎ∞± ‚Üí Îã®Ïùº Í≥µÎ∞±)
   ‚Ä¢ Ïò§ÌÉÄ ÍµêÏ†ï (extention ‚Üí extension Îì±)

2. timeFrame ÌååÏã±:
   ‚úÖ ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥:
      - Baseline Ìè¨Ìï®: "Baseline, Week 16" ‚Üí change_from_baseline_flag = TRUE
      - At Day/Week/Month N: "At Day 1", "At Week 14", "At Month 12" ‚Üí N, day/week/month
      - Day/Month/Week N Îã®ÎèÖ: "Day 1", "Month 3", "Week 12" ‚Üí N, day/month/week
      - Day N to/through M: "Day 1 to day 30", "Day 1 through 7" ‚Üí ÏãúÏûëÏùº, Ï¢ÖÎ£åÏùº Ï∂îÏ∂ú
      - For N Months/Weeks/Days: "For 10 Months" ‚Üí 10, month
      - At Months N and M: "At Months 6 and 12" ‚Üí Î≥µÏàò ÏãúÏ†ê Ï∂îÏ∂ú
      - ÌÖçÏä§Ìä∏ Ïà´Ïûê+Îã®ÏúÑ: "Two years", "eight weeks" ‚Üí 2, year / 8, week
      - Ïà´Ïûê+Îã®ÏúÑ: "26 weeks" ‚Üí 26, weeks
      - Year N: "Year 3.5" ‚Üí 3.5, year
      - Up to: "up to 72 hours" ‚Üí 72, hour
      - Through: "through study completion, an average of 1 year" ‚Üí 1, year
   
   ‚ùå ÌååÏã± Ïñ¥Î†§Ïö¥ Ìå®ÌÑ¥:
      - "% of exact responses" (ÏùëÎãµÎ•†)
      - "The time to respond" (ÏãúÍ∞Ñ/ÏÜçÎèÑ)
      - "0 Hour (pre-dose) on Day 1" (Î≥µÏû°Ìïú ÏãúÏ†ê ÌëúÌòÑ)
      - "3 Days in each of the 4 dosing session" (Î≥µÏû°Ìïú Ï°∞Í±¥Î∂Ä ÌëúÌòÑ)
      - Í∏∞ÌÉÄ ÎπÑÌëúÏ§Ä ÌëúÌòÑ

3. change_from_baseline ÌîåÎûòÍ∑∏:
   ‚Ä¢ descriptionÏóêÏÑú "change from baseline" Ìå®ÌÑ¥ Í≤ÄÏÉâ
   ‚Ä¢ Î∞úÍ≤¨ Ïãú ÌîåÎûòÍ∑∏ = TRUE

4. Phase ÌÉúÍπÖ:
   ‚Ä¢ double-blind, extension, follow-up Îì± ÌÇ§ÏõåÎìú Ï∂îÏ∂ú
""")
    
    # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
    excel_data['normalization_rules'] = {
        'text_cleaning': {
            'description': 'Í≥µÎ∞± Ï†ïÎ¶¨, Ïò§ÌÉÄ ÍµêÏ†ï',
            'rules': ['Ïó∞ÏÜç Í≥µÎ∞± ‚Üí Îã®Ïùº Í≥µÎ∞±', 'extention ‚Üí extension']
        },
        'timeframe_parsing': {
            'parseable_patterns': [
                'Baseline Ìè¨Ìï®: "Baseline, Week 16" ‚Üí change_from_baseline_flag = TRUE',
                'At Day/Week/Month N: "At Day 1", "At Week 14", "At Month 12" ‚Üí N, day/week/month',
                'Day/Month/Week N Îã®ÎèÖ: "Day 1", "Month 3", "Week 12" ‚Üí N, day/month/week',
                'Day N to/through M: "Day 1 to day 30", "Day 1 through 7" ‚Üí ÏãúÏûëÏùº, Ï¢ÖÎ£åÏùº Ï∂îÏ∂ú',
                'For N Months/Weeks/Days: "For 10 Months" ‚Üí 10, month',
                'At Months N and M: "At Months 6 and 12" ‚Üí Î≥µÏàò ÏãúÏ†ê Ï∂îÏ∂ú',
                'ÌÖçÏä§Ìä∏ Ïà´Ïûê+Îã®ÏúÑ: "Two years", "eight weeks" ‚Üí 2, year / 8, week',
                'Ïà´Ïûê+Îã®ÏúÑ: "26 weeks" ‚Üí 26, weeks',
                'Year N: "Year 3.5" ‚Üí 3.5, year',
                'Up to: "up to 72 hours" ‚Üí 72, hour',
                'Through: "through study completion, an average of 1 year" ‚Üí 1, year'
            ],
            'baseline_patterns': [
                'Baseline, Week 16 ‚Üí change_from_baseline_flag = TRUE',
                'Baseline (Week 1 [Day 1]), Week 16 ‚Üí change_from_baseline_flag = TRUE'
            ],
            'unparseable_patterns': [
                '% of exact responses (ÏùëÎãµÎ•†)',
                'The time to respond (ÏãúÍ∞Ñ/ÏÜçÎèÑ)',
                'Í∏∞ÌÉÄ ÎπÑÌëúÏ§Ä ÌëúÌòÑ'
            ]
        },
        'change_from_baseline': {
            'description': 'descriptionÏóêÏÑú "change from baseline" Ìå®ÌÑ¥ Í≤ÄÏÉâ',
            'patterns': [
                'change from baseline',
                'change of .* from baseline',
                'difference from baseline'
            ]
        },
        'phase_tagging': {
            'keywords': ['double-blind', 'extension', 'follow-up', 'open-label']
        }
    }


def analyze_unparseable_by_party(conn):
    """ÌååÏã± Î∂àÍ∞ÄÎä•Ìïú Í≤ÉÎì§ÏùÑ Í∏∞Í¥Ä/Îã¥ÎãπÏûêÎ≥ÑÎ°ú ÏõêÏù∏ Î∂ÑÏÑù"""
    print("\n" + "=" * 80)
    print("üî¨ ÌååÏã± Î∂àÍ∞ÄÎä• ÏºÄÏù¥Ïä§ - Í∏∞Í¥Ä/Îã¥ÎãπÏûêÎ≥Ñ ÏõêÏù∏ Î∂ÑÏÑù")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # LEAD_SPONSORÎ≥Ñ ÌååÏã± Ïã§Ìå® ÏºÄÏù¥Ïä§ Î∂ÑÏÑù
        print("\n[LEAD_SPONSORÎ≥Ñ ÌååÏã± Ïã§Ìå® ÏºÄÏù¥Ïä§]")
        cur.execute("""
            SELECT 
                sp.name_raw as sponsor_name,
                sp.class_raw as sponsor_class,
                COUNT(*) as total_outcomes,
                COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END) as null_count,
                COUNT(CASE WHEN o.time_frame_raw IS NOT NULL 
                          AND o.time_frame_raw != ''
                          -- ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Î™®Îëê Ï†úÏô∏
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)')
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '\\d+\\s*-?\\s*(day|days|week|weeks|month|months|year|years|hour|hours|hr|hrs)')
                          AND NOT (o.time_frame_raw ~* 'at\\s+(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'day\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+')
                          AND NOT (o.time_frame_raw ~* 'for\\s+\\d+\\s+(month|months|week|weeks|day|days)')
                          AND NOT (o.time_frame_raw ~* 'at\\s+months?\\s+\\d+\\s+and\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)')
                          AND NOT (o.time_frame_raw ~* 'year\\s*\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+(day|days|week|weeks|month|months|year|years)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(week|weeks|day|days|month|months)\\s+\\d+.*?,\\s*(week|weeks|day|days|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)')
                          THEN 1 END) as unparseable_count
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'LEAD_SPONSOR'
            GROUP BY sp.name_raw, sp.class_raw
            HAVING COUNT(CASE WHEN o.time_frame_raw IS NOT NULL 
                          AND o.time_frame_raw != ''
                          -- ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Î™®Îëê Ï†úÏô∏
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)')
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '\\d+\\s*-?\\s*(day|days|week|weeks|month|months|year|years|hour|hours|hr|hrs)')
                          AND NOT (o.time_frame_raw ~* 'at\\s+(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'day\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+')
                          AND NOT (o.time_frame_raw ~* 'for\\s+\\d+\\s+(month|months|week|weeks|day|days)')
                          AND NOT (o.time_frame_raw ~* 'at\\s+months?\\s+\\d+\\s+and\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)')
                          AND NOT (o.time_frame_raw ~* 'year\\s*\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+(day|days|week|weeks|month|months|year|years)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(week|weeks|day|days|month|months)\\s+\\d+.*?,\\s*(week|weeks|day|days|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)')
                          THEN 1 END) > 0
            ORDER BY unparseable_count DESC
            LIMIT 20
        """)
        
        sponsor_failures = cur.fetchall()
        
        print(f"{'ÏàúÏúÑ':<5} {'Ïä§Ìè∞ÏÑúÎ™Ö':<40} {'ÌÅ¥ÎûòÏä§':<15} {'Total':<10} {'Null':<10} {'Unparseable':<15} {'Ïã§Ìå®Ïú®':<10}")
        print("-" * 110)
        
        for i, row in enumerate(sponsor_failures, 1):
            sponsor_name = (row['sponsor_name'] or 'N/A')[:38]
            sponsor_class = (row['sponsor_class'] or 'N/A')[:13]
            total = row['total_outcomes']
            null_count = row['null_count']
            unparseable = row['unparseable_count']
            valid_count = total - null_count
            failure_rate = (unparseable / valid_count * 100) if valid_count > 0 else 0
            
            print(f"{i:<5} {sponsor_name:<40} {sponsor_class:<15} {total:<10} {null_count:<10} "
                  f"{unparseable:<15} {failure_rate:<9.1f}%")
            
            # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['unparseable_by_sponsor'] = excel_data.get('unparseable_by_sponsor', [])
            excel_data['unparseable_by_sponsor'].append({
                'rank': i,
                'sponsor_name': row['sponsor_name'],
                'sponsor_class': row['sponsor_class'],
                'total_outcomes': total,
                'null_count': null_count,
                'unparseable_count': unparseable,
                'failure_rate': failure_rate
            })
        
        # ÌååÏã± Ïã§Ìå® ÏºÄÏù¥Ïä§ ÏÉòÌîå Ï∂îÏ∂ú (timeFrame + measure Î™®Îëê)
        print("\n[ÌååÏã± Ïã§Ìå® ÏºÄÏù¥Ïä§ ÏÉòÌîå]")
        
        # timeFrame ÌååÏã± Ïã§Ìå® ÏÉòÌîå (ÎπàÎèÑÏàò Ìè¨Ìï®)
        print("\nüìå timeFrame ÌååÏã± Ïã§Ìå® ÏÉòÌîå (Top 20):")
        cur.execute("""
            SELECT 
                o.time_frame_raw,
                COUNT(*) as frequency
            FROM outcome_raw o
            WHERE o.time_frame_raw IS NOT NULL 
              AND o.time_frame_raw != ''
              -- ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Î™®Îëê Ï†úÏô∏
              AND NOT (o.time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)')
              AND NOT (o.time_frame_raw ~* '(^|[^a-z])(day|days|week|weeks|month|months)\\s+\\d+')
              AND NOT (o.time_frame_raw ~* '\\d+\\s*-?\\s*(day|days|week|weeks|month|months|year|years|hour|hours|hr|hrs)')
              AND NOT (o.time_frame_raw ~* 'at\\s+(day|days|week|weeks|month|months)\\s+\\d+')
              AND NOT (o.time_frame_raw ~* 'day\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+')
              AND NOT (o.time_frame_raw ~* 'for\\s+\\d+\\s+(month|months|week|weeks|day|days)')
              AND NOT (o.time_frame_raw ~* 'at\\s+months?\\s+\\d+\\s+and\\s+\\d+')
              AND NOT (o.time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)')
              AND NOT (o.time_frame_raw ~* 'year\\s*\\d+')
              AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+\\d+')
              AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+(day|days|week|weeks|month|months|year|years)\\s+\\d+')
              AND NOT (o.time_frame_raw ~* '(week|weeks|day|days|month|months)\\s+\\d+.*?,\\s*(week|weeks|day|days|month|months)\\s+\\d+')
              AND NOT (o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)')
            GROUP BY o.time_frame_raw
            ORDER BY frequency DESC
            LIMIT 20
        """)
        
        timeframe_samples = cur.fetchall()
        for i, sample in enumerate(timeframe_samples, 1):
            tf = sample['time_frame_raw']
            freq = sample['frequency']
            display_text = tf[:100] + "..." if len(tf) > 100 else tf
            print(f"  {i:2d}. [{freq:4d}Í±¥] {display_text}")
        
        # measure ÏïΩÏñ¥ Ï∂îÏ∂ú Ïã§Ìå® ÏÉòÌîå (ÎπàÎèÑÏàò Ìè¨Ìï®)
        print("\nüìå measure ÏïΩÏñ¥ Ï∂îÏ∂ú Ïã§Ìå® ÏÉòÌîå (Top 20):")
        cur.execute("""
            SELECT 
                o.measure_raw,
                COUNT(*) as frequency
            FROM outcome_raw o
            WHERE o.measure_raw IS NOT NULL 
              AND o.measure_raw != ''
              AND o.measure_raw !~ '\\([A-Za-z][A-Za-z0-9\\-+\\s/]+\\)'
            GROUP BY o.measure_raw
            ORDER BY frequency DESC
            LIMIT 20
        """)
        
        measure_samples = cur.fetchall()
        for i, sample in enumerate(measure_samples, 1):
            measure = sample['measure_raw']
            freq = sample['frequency']
            display_text = measure[:100] + "..." if len(measure) > 100 else measure
            print(f"  {i:2d}. [{freq:4d}Í±¥] {display_text}")
        
        # OFFICIALÎ≥Ñ ÌååÏã± Ïã§Ìå® ÏºÄÏù¥Ïä§ Î∂ÑÏÑù
        print("\n" + "-" * 80)
        print("[OFFICIALÎ≥Ñ ÌååÏã± Ïã§Ìå® ÏºÄÏù¥Ïä§]")
        cur.execute("""
            SELECT 
                sp.name_raw as official_name,
                sp.affiliation_raw as affiliation,
                COUNT(*) as total_outcomes,
                COUNT(CASE WHEN o.time_frame_raw IS NULL OR o.time_frame_raw = '' THEN 1 END) as null_count,
                COUNT(CASE WHEN o.time_frame_raw IS NOT NULL 
                          AND o.time_frame_raw != ''
                          -- ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Î™®Îëê Ï†úÏô∏
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)')
                          AND NOT (o.time_frame_raw ~* '\\bat\\s+(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '\\b(day|days|month|months|week|weeks)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '\\bday\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+')
                          AND NOT (o.time_frame_raw ~* '\\bfor\\s+\\d+\\s+(month|months|week|weeks|day|days)')
                          AND NOT (o.time_frame_raw ~* '\\bat\\s+months?\\s+\\d+\\s+and\\s+\\d+')
                          AND NOT (o.time_frame_raw ~ '\\d+\\s*-?\\s*(week|weeks|month|months|year|years|day|days|hour|hours|hr|hrs)')
                          AND NOT (o.time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)')
                          AND NOT (o.time_frame_raw ~* 'year\\s*\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+(day|days|week|weeks|month|months|year|years)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(week|weeks|day|days|month|months)\\s+\\d+.*?,\\s*(week|weeks|day|days|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)')
                          THEN 1 END) as unparseable_count
            FROM outcome_raw o
            INNER JOIN study_party_raw sp ON o.nct_id = sp.nct_id
            WHERE sp.party_type = 'OFFICIAL'
            GROUP BY sp.name_raw, sp.affiliation_raw
            HAVING COUNT(CASE WHEN o.time_frame_raw IS NOT NULL 
                          AND o.time_frame_raw != ''
                          -- ÌååÏã± Í∞ÄÎä•Ìïú Ìå®ÌÑ¥ Î™®Îëê Ï†úÏô∏
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])baseline([^a-z]|$)')
                          AND NOT (o.time_frame_raw ~* '(^|[^a-z])(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '\\d+\\s*-?\\s*(day|days|week|weeks|month|months|year|years|hour|hours|hr|hrs)')
                          AND NOT (o.time_frame_raw ~* 'at\\s+(day|days|week|weeks|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'day\\s+\\d+\\s+(to|through)\\s+(day\\s+)?\\d+')
                          AND NOT (o.time_frame_raw ~* 'for\\s+\\d+\\s+(month|months|week|weeks|day|days)')
                          AND NOT (o.time_frame_raw ~* 'at\\s+months?\\s+\\d+\\s+and\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred)\\s+(week|weeks|month|months|year|years|day|days|hour|hours)')
                          AND NOT (o.time_frame_raw ~* 'year\\s*\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'up\\s*to\\s+(day|days|week|weeks|month|months|year|years)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* '(week|weeks|day|days|month|months)\\s+\\d+.*?,\\s*(week|weeks|day|days|month|months)\\s+\\d+')
                          AND NOT (o.time_frame_raw ~* 'through.*completion.*\\d+\\s*(week|weeks|month|months|year|years)')
                          THEN 1 END) > 0
            ORDER BY unparseable_count DESC
            LIMIT 15
        """)
        
        official_failures = cur.fetchall()
        
        print(f"{'ÏàúÏúÑ':<5} {'Îã¥ÎãπÏûêÎ™Ö':<30} {'ÏÜåÏÜç':<35} {'Total':<10} {'Unparseable':<15} {'Ïã§Ìå®Ïú®':<10}")
        print("-" * 110)
        
        for i, row in enumerate(official_failures, 1):
            official_name = (row['official_name'] or 'N/A')[:28]
            affiliation = (row['affiliation'] or 'N/A')[:33]
            total = row['total_outcomes']
            null_count = row['null_count']
            unparseable = row['unparseable_count']
            valid_count = total - null_count
            failure_rate = (unparseable / valid_count * 100) if valid_count > 0 else 0
            
            print(f"{i:<5} {official_name:<30} {affiliation:<35} {total:<10} "
                  f"{unparseable:<15} {failure_rate:<9.1f}%")
            
            # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            excel_data['unparseable_by_official'] = excel_data.get('unparseable_by_official', [])
            excel_data['unparseable_by_official'].append({
                'rank': i,
                'official_name': row['official_name'],
                'affiliation': row['affiliation'],
                'total_outcomes': total,
                'null_count': null_count,
                'unparseable_count': unparseable,
                'failure_rate': failure_rate
            })


def generate_summary_report(conn):
    """Ï¢ÖÌï© Î¶¨Ìè¨Ìä∏"""
    print("\n" + "=" * 80)
    print("üìä Ï¢ÖÌï© Î¶¨Ìè¨Ìä∏")
    print("=" * 80)
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Í∏∞Î≥∏ ÌÜµÍ≥Ñ
        cur.execute("""
            SELECT 
                COUNT(DISTINCT o.nct_id) as total_studies,
                COUNT(*) as total_outcomes,
                COUNT(CASE WHEN o.outcome_type = 'PRIMARY' THEN 1 END) as primary_count,
                COUNT(CASE WHEN o.outcome_type = 'SECONDARY' THEN 1 END) as secondary_count
            FROM outcome_raw o
        """)
        summary = cur.fetchone()
        
        cur.execute("""
            SELECT AVG(outcome_count) as avg_outcomes
            FROM (
                SELECT o.nct_id, COUNT(*) as outcome_count
                FROM outcome_raw o
                GROUP BY o.nct_id
            ) subq
        """)
        avg_outcomes = cur.fetchone()['avg_outcomes']
        
        print(f"\nüìä Í∏∞Î≥∏ ÌÜµÍ≥Ñ:")
        print(f"  Ï¥ù Studies: {summary['total_studies']:,}Í±¥")
        print(f"  Ï¥ù Outcomes: {summary['total_outcomes']:,}Í±¥")
        print(f"  StudyÎãπ ÌèâÍ∑† Outcomes: {avg_outcomes:.1f}Í∞ú")
        if summary['total_outcomes'] > 0:
            print(f"  PRIMARY: {summary['primary_count']:,}Í±¥ ({summary['primary_count']/summary['total_outcomes']*100:.1f}%)")
            print(f"  SECONDARY: {summary['secondary_count']:,}Í±¥ ({summary['secondary_count']/summary['total_outcomes']*100:.1f}%)")
        
        # Excel Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        excel_data['summary'] = {
            'total_studies': summary['total_studies'],
            'total_outcomes': summary['total_outcomes'],
            'avg_outcomes_per_study': float(avg_outcomes) if avg_outcomes else 0,
            'primary_count': summary['primary_count'],
            'secondary_count': summary['secondary_count'],
            'primary_pct': summary['primary_count']/summary['total_outcomes']*100 if summary['total_outcomes'] > 0 else 0,
            'secondary_pct': summary['secondary_count']/summary['total_outcomes']*100 if summary['total_outcomes'] > 0 else 0
        }


def save_to_json():
    """Excel ÏÉùÏÑ±ÏùÑ ÏúÑÌïú JSON ÌååÏùº Ï†ÄÏû•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_filename = f"diagnosis_data_{timestamp}.json"
    
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(excel_data, f, ensure_ascii=False, indent=2, default=str)
    
    return json_filename


def main():
    """Î©îÏù∏ Ìï®Ïàò"""
    import sys
    from io import StringIO
    
    # Ï∂úÎ†•ÏùÑ Ï∫°Ï≤òÌïòÍ∏∞ ÏúÑÌïú StringIO
    output_buffer = StringIO()
    original_stdout = sys.stdout
    
    class TeeOutput:
        """Ï∂úÎ†•ÏùÑ ÌôîÎ©¥Í≥º Î≤ÑÌçºÏóê ÎèôÏãúÏóê Ïì∞Í∏∞"""
        def __init__(self, *files):
            self.files = files
        def write(self, obj):
            for f in self.files:
                f.write(obj)
                f.flush()
        def flush(self):
            for f in self.files:
                f.flush()
    
    print("=" * 80)
    print("üîç ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ ÏßÑÎã® ÏãúÏûë")
    print("=" * 80)
    
    try:
        # Excel Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨Î•º diagnosis_queries Î™®ÎìàÏóê ÏÑ§Ï†ï
        set_excel_data(excel_data)
        
        conn = get_db_connection()
        
        # Îç∞Ïù¥ÌÑ∞ Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏
        with conn.cursor() as cur:
            cur.execute("SELECT COUNT(*) FROM outcome_raw")
            outcome_count = cur.fetchone()[0]
            
            cur.execute("SELECT COUNT(*) FROM study_party_raw WHERE party_type IN ('LEAD_SPONSOR', 'OFFICIAL')")
            party_count = cur.fetchone()[0]
            
            if outcome_count == 0:
                print("\n[ERROR] outcome_raw ÌÖåÏù¥Î∏îÏóê Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§!")
                print("Î®ºÏ†Ä collect_outcomes.pyÎ•º Ïã§ÌñâÌïòÏó¨ Îç∞Ïù¥ÌÑ∞Î•º ÏàòÏßëÌïòÏÑ∏Ïöî.")
                return
            
            print(f"\nüìã Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏:")
            print(f"  Outcomes: {outcome_count:,}Í±¥")
            print(f"  Party records (LEAD_SPONSOR/OFFICIAL): {party_count:,}Í±¥")
        
        # Ï∂úÎ†•ÏùÑ ÌôîÎ©¥Í≥º Î≤ÑÌçºÏóê ÎèôÏãúÏóê
        sys.stdout = TeeOutput(original_stdout, output_buffer)
        
        # Í∞Å Î∂ÑÏÑù Ïã§Ìñâ
        analyze_null_values(conn)  # 1. Ïª¨ÎüºÎ≥Ñ ÎàÑÎùΩ Í±¥Ïàò
        explain_normalization_rules()  # 2. Ï†ïÍ∑úÌôî Î£∞ ÏÑ§Î™Ö
        analyze_party_overview(conn)  # Í∏∞Í¥Ä/Îã¥ÎãπÏûê Ï†ÑÏ≤¥ ÌÜµÍ≥Ñ
        analyze_timeframe_patterns(conn)
        analyze_measure_patterns(conn)
        analyze_measure_by_study(conn)  # measure ÏïΩÏñ¥ Ï∂îÏ∂ú - Study Îã®ÏúÑ
        analyze_timeframe_by_study(conn)  # timeFrame ÌååÏã± - Study Îã®ÏúÑ
        analyze_description_patterns(conn)
        analyze_unparseable_by_party(conn)  # 4. ÌååÏã± Î™ªÌïòÎäî Í≤ÉÎì§ Í∏∞Í¥Ä/Îã¥ÎãπÏûêÎ≥Ñ ÏõêÏù∏ Î∂ÑÏÑù
        analyze_by_lead_sponsor(conn)  # Í∏∞Í¥ÄÎ≥Ñ ÏÉÅÏÑ∏ Î∂ÑÏÑù (ÌååÏã± Í∞ÄÎä•ÏÑ± Ìè¨Ìï®)
        analyze_by_official(conn)  # Îã¥ÎãπÏûêÎ≥Ñ ÏÉÅÏÑ∏ Î∂ÑÏÑù (ÌååÏã± Í∞ÄÎä•ÏÑ± Ìè¨Ìï®)
        analyze_sponsor_class_patterns(conn)
        analyze_failure_rates_by_party(conn)
        generate_summary_report(conn)
        
        print("\n" + "=" * 80)
        print("‚úÖ ÏßÑÎã® ÏôÑÎ£å!")
        print("=" * 80)
        
        # ÏõêÎûò stdoutÏúºÎ°ú Î≥µÍµ¨
        sys.stdout = original_stdout
        
        # MD ÌååÏùºÎ°ú Ï†ÄÏû•
        output_content = output_buffer.getvalue()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        md_filename = f"diagnosis_complete_{timestamp}.md"
        
        with open(md_filename, 'w', encoding='utf-8') as f:
            f.write(f"# ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ ÏßÑÎã® Í≤∞Í≥º\n\n")
            f.write(f"**ÏÉùÏÑ± ÏãúÍ∞Ñ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            f.write("```\n")
            f.write(output_content)
            f.write("\n```\n")
        
        # Excel ÏÉùÏÑ±ÏùÑ ÏúÑÌïú JSON ÌååÏùº Ï†ÄÏû•
        json_filename = save_to_json()
        
        print(f"\nüìÑ ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å:")
        print(f"  ‚Ä¢ MD Î¶¨Ìè¨Ìä∏: {md_filename}")
        print(f"  ‚Ä¢ ExcelÏö© Îç∞Ïù¥ÌÑ∞: {json_filename}")
        print(f"\nüí° Îã§Ïùå Îã®Í≥Ñ:")
        print(f"  1. {json_filename} ÌååÏùºÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Excel Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±")
        print(f"  2. ÏßÑÎã® Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú Ï†ïÍ∑úÌôî Í∑úÏπô ÏÑ§Í≥Ñ")
        
        conn.close()
        
    except Exception as e:
        print(f"\n[ERROR] Ïò§Î•ò Î∞úÏÉù: {e}")
        import traceback
        traceback.print_exc()
        sys.stdout = original_stdout
        if 'conn' in locals():
            conn.close()
    finally:
        if 'output_buffer' in locals():
            output_buffer.close()


if __name__ == "__main__":
    main()

