"""
ì „ì²´ ë°ì´í„° LLM ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

outcome_raw í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ LLMìœ¼ë¡œ ì „ì²˜ë¦¬í•˜ì—¬ 
outcome_llm_preprocessed í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import json
import time
from typing import Dict, Optional, List
import psycopg2
from psycopg2.extras import RealDictCursor, execute_batch
from dotenv import load_dotenv
from llm_config import (
    get_api_keys, GEMINI_MODEL,
    MAX_REQUESTS_PER_MINUTE, BATCH_SIZE, MAX_RETRIES, RETRY_DELAY
)
from llm_prompts import get_preprocess_initial_prompt

load_dotenv()

DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'clinicaltrials'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', '')
}


def get_db_connection():
    """PostgreSQL ì—°ê²° ìƒì„±"""
    return psycopg2.connect(**DB_CONFIG)


def call_gemini_api(prompt: str) -> Optional[Dict]:
    """Gemini API í˜¸ì¶œ (ì—¬ëŸ¬ API í‚¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„, 429 ì—ëŸ¬ ì‹œ ìë™ ì „í™˜)"""
    api_keys = get_api_keys()
    if not api_keys:
        print("[ERROR] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        return None
    
    # í˜„ì¬ ì „ì—­ í‚¤ ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘
    import llm_config
    start_key_index = llm_config._current_key_index
    
    last_error = None
    
    # ëª¨ë“  í‚¤ë¥¼ ì‹œë„
    for attempt in range(len(api_keys)):
        key_index = (start_key_index + attempt) % len(api_keys)
        
        try:
            # íŠ¹ì • í‚¤ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            from google import genai
            client = genai.Client(api_key=api_keys[key_index])
            response = client.models.generate_content(
                model=GEMINI_MODEL,
                contents=prompt
            )
            
            # ì„±ê³µ ì‹œ ì „ì—­ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            if llm_config._current_key_index != key_index:
                llm_config._previous_key_index = llm_config._current_key_index
                llm_config._current_key_index = key_index
            else:
                llm_config._current_key_index = key_index
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            content = response.text.strip()
            
            # ì½”ë“œ ë¸”ë¡ ì œê±° (```json ë˜ëŠ” ```ë¡œ ê°ì‹¸ì§„ ê²½ìš°)
            if '```' in content:
                # ```json ë˜ëŠ” ```ë¡œ ì‹œì‘í•˜ëŠ” ë¸”ë¡ ì°¾ê¸°
                import re
                # ì½”ë“œ ë¸”ë¡ íŒ¨í„´ ë§¤ì¹­
                code_block_pattern = r'```(?:json)?\s*\n(.*?)\n```'
                match = re.search(code_block_pattern, content, re.DOTALL)
                if match:
                    content = match.group(1).strip()
                else:
                    # ë‹¨ìˆœíˆ ``` ì œê±°
                    content = re.sub(r'```(?:json)?', '', content).strip()
            
            # JSON ë°°ì—´ ì‹œì‘ ë¶€ë¶„ ì°¾ê¸° (ì²« ë²ˆì§¸ '[' ìœ„ì¹˜)
            json_start = content.find('[')
            if json_start >= 0:
                content = content[json_start:]
            else:
                # '['ê°€ ì—†ìœ¼ë©´ JSON ê°ì²´ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
                json_start = content.find('{')
                if json_start >= 0:
                    # ë‹¨ì¼ ê°ì²´ë¥¼ ë°°ì—´ë¡œ ê°ì‹¸ê¸°
                    content = '[' + content[json_start:]
                    # ë§ˆì§€ë§‰ '}' ë’¤ì— ']' ì¶”ê°€
                    json_end = content.rfind('}')
                    if json_end >= 0:
                        content = content[:json_end + 1] + ']'
            
            # JSON ë°°ì—´ ë ë¶€ë¶„ ì°¾ê¸° (ë§ˆì§€ë§‰ ']' ìœ„ì¹˜)
            json_end = content.rfind(']')
            if json_end >= 0:
                content = content[:json_end + 1]
            
            # ì•ë’¤ ê³µë°± ë° ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            content = content.strip()
            
            try:
                parsed = json.loads(content)
                # ë°°ì—´ì´ ì•„ë‹Œ ê²½ìš° ë°°ì—´ë¡œ ë³€í™˜
                if not isinstance(parsed, list):
                    parsed = [parsed]
                return parsed
            except json.JSONDecodeError as e:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ íŒŒì‹± ì‹œë„
                print(f"[WARN] JSON íŒŒì‹± ì‹¤íŒ¨ (í‚¤ {key_index + 1}/{len(api_keys)}): {e}")
                print(f"  ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {content[:500]}")
                
                # ì˜ë¦° JSON ë³µêµ¬ ì‹œë„
                try:
                    import re
                    # ì¤‘ì²©ëœ JSON ê°ì²´ë¥¼ í¬í•¨í•œ íŒ¨í„´ (ë” ì •êµí•œ ë§¤ì¹­)
                    # ê° ê°ì²´ë¥¼ ì°¾ë˜, ì¤‘ì²©ëœ êµ¬ì¡°ë„ ì²˜ë¦¬
                    parsed_items = []
                    brace_count = 0
                    start_pos = -1
                    current_obj = ""
                    
                    # '{'ì™€ '}'ë¥¼ ì¶”ì í•˜ì—¬ ì™„ì „í•œ JSON ê°ì²´ ì°¾ê¸°
                    for i, char in enumerate(content):
                        if char == '{':
                            if brace_count == 0:
                                start_pos = i
                            brace_count += 1
                            current_obj += char
                        elif char == '}':
                            current_obj += char
                            brace_count -= 1
                            if brace_count == 0:
                                # ì™„ì „í•œ ê°ì²´ ë°œê²¬
                                try:
                                    obj = json.loads(current_obj)
                                    if isinstance(obj, dict) and 'outcome_id' in obj:
                                        parsed_items.append(obj)
                                except json.JSONDecodeError:
                                    pass
                                current_obj = ""
                                start_pos = -1
                        elif start_pos >= 0:
                            current_obj += char
                    
                    # ì •ê·œì‹ìœ¼ë¡œë„ ì‹œë„ (ê°„ë‹¨í•œ ê²½ìš°)
                    if not parsed_items:
                        json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
                        for obj_str in json_objects:
                            try:
                                obj = json.loads(obj_str)
                                if isinstance(obj, dict) and 'outcome_id' in obj:
                                    parsed_items.append(obj)
                            except json.JSONDecodeError:
                                continue
                    
                    if parsed_items:
                        print(f"  [ë³µêµ¬] {len(parsed_items)}ê°œ í•­ëª©ì„ ë¶€ë¶„ íŒŒì‹±í•˜ì—¬ ë³µêµ¬í–ˆìŠµë‹ˆë‹¤.")
                        # ë³µêµ¬ëœ í•­ëª©ì— ë³µêµ¬ í‘œì‹œ ì¶”ê°€
                        for item in parsed_items:
                            if 'notes' in item:
                                item['notes'] = f"[PARTIAL_RECOVERED] {item.get('notes', '')}"
                            else:
                                item['notes'] = '[PARTIAL_RECOVERED] JSON íŒŒì‹± ì‹¤íŒ¨ í›„ ë¶€ë¶„ ë³µêµ¬ ì„±ê³µ.'
                        return parsed_items
                except Exception as recover_error:
                    print(f"  [ë³µêµ¬ ì‹¤íŒ¨] {recover_error}")
                
                # ë³µêµ¬ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
                return None
            
        except Exception as e:
            error_str = str(e)
            last_error = e
            
            # 429 ì—ëŸ¬ (RESOURCE_EXHAUSTED) ì²´í¬
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str.upper():
                print(f"âš ï¸  API í‚¤ {key_index + 1}/{len(api_keys)}ì—ì„œ 429 ì—ëŸ¬ ë°œìƒ (ì‹œë„ {attempt + 1}/{len(api_keys)}): {error_str}")
                
                if attempt == len(api_keys) - 1:
                    print(f"[ERROR] ëª¨ë“  API í‚¤({len(api_keys)}ê°œ)ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    llm_config._previous_key_index = llm_config._current_key_index
                    llm_config._current_key_index = key_index
                    llm_config._all_keys_exhausted = True
                    return None
                else:
                    next_key_index = (start_key_index + attempt + 1) % len(api_keys)
                    print(f"ğŸ”„ ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜í•©ë‹ˆë‹¤ (í‚¤ {next_key_index + 1}/{len(api_keys)})")
                    continue
            else:
                print(f"[ERROR] Gemini API ì˜¤ë¥˜ (í‚¤ {key_index + 1}/{len(api_keys)}): {error_str}")
                return None
    
    print(f"[ERROR] ëª¨ë“  API í‚¤({len(api_keys)}ê°œ) ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì—ëŸ¬: {str(last_error)}")
    llm_config._all_keys_exhausted = True
    return None


def determine_llm_status(measure_code, time_value, time_unit, notes: str = None, has_time_frame_raw: bool = True) -> tuple:
    """
    LLM ì²˜ë¦¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒíƒœì™€ ì‹¤íŒ¨ ì´ìœ  ê²°ì •
    
    Args:
        measure_code: ì¶”ì¶œëœ measure_code
        time_value: ì¶”ì¶œëœ time_value
        time_unit: ì¶”ì¶œëœ time_unit
        notes: LLM ì‘ë‹µì˜ notes
        has_time_frame_raw: ì›ë³¸ì— time_frame_rawê°€ ìˆëŠ”ì§€ ì—¬ë¶€
    
    Returns:
        (llm_status, failure_reason, formatted_notes, time_value, time_unit)
    """
    has_measure = measure_code is not None and measure_code != ''
    has_time = time_value is not None and time_unit is not None
    
    # notes í˜•ì‹í™”
    formatted_notes = notes or ''
    
    # time_frame_rawê°€ ì—†ëŠ” ê²½ìš°: time_value=0, time_unit=nullë¡œ ì²˜ë¦¬í•˜ë˜ SUCCESSë¡œ ì²˜ë¦¬
    if has_measure and not has_time_frame_raw:
        status = 'SUCCESS'
        failure_reason = None
        time_value = 0
        time_unit = None
        if not formatted_notes:
            formatted_notes = '[SUCCESS] measure_code ì¶”ì¶œ ì„±ê³µ. time_frame ì •ë³´ ì—†ìŒ (time_value=0).'
        return status, failure_reason, formatted_notes, time_value, time_unit
    
    if has_measure and has_time:
        status = 'SUCCESS'
        failure_reason = None
        if not formatted_notes:
            formatted_notes = '[SUCCESS] measure_codeì™€ time ì •ë³´ ëª¨ë‘ ì¶”ì¶œ ì„±ê³µ.'
    elif not has_measure and not has_time:
        status = 'BOTH_FAILED'
        failure_reason = 'BOTH_FAILED'
        if not formatted_notes:
            formatted_notes = '[BOTH_FAILED] measure_codeì™€ time ì •ë³´ ëª¨ë‘ ì¶”ì¶œ ì‹¤íŒ¨.'
    elif not has_measure:
        status = 'MEASURE_FAILED'
        failure_reason = 'MEASURE_FAILED'
        if not formatted_notes:
            formatted_notes = '[MEASURE_FAILED] measure_code ì¶”ì¶œ ì‹¤íŒ¨.'
    else:  # not has_time
        status = 'TIMEFRAME_FAILED'
        failure_reason = 'TIMEFRAME_FAILED'
        if not formatted_notes:
            formatted_notes = '[TIMEFRAME_FAILED] time ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨.'
    
    return status, failure_reason, formatted_notes, time_value, time_unit


def preprocess_batch_outcomes(outcomes: List[Dict]) -> List[Dict]:
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ outcomeë“¤ì„ LLMìœ¼ë¡œ ì „ì²˜ë¦¬"""
    if not outcomes:
        return []
    
    # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    items = []
    for outcome in outcomes:
        oid = outcome.get('id')  # outcome_rawëŠ” id ì‚¬ìš©
        mr = outcome.get('measure_raw', '') or ''
        dr = outcome.get('description_raw', '') or ''
        tr = outcome.get('time_frame_raw', '') or ''
        # ë¹ˆ ê°’ ìƒëµí•˜ì—¬ ë” ì§§ê²Œ
        parts = [f"{oid}"]
        if mr: parts.append(f"M:{mr}")
        if dr: parts.append(f"D:{dr}")
        if tr: parts.append(f"T:{tr}")
        item_str = "|".join(parts)
        items.append(item_str)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    items_text = '\n'.join(items)
    prompt = get_preprocess_initial_prompt(items_text)
    
    result = call_gemini_api(prompt)
    
    if not result:
        # API ì‹¤íŒ¨ ì‹œ ëª¨ë‘ null ì²˜ë¦¬
        return [{
            'outcome_id': outcome.get('id'),
            'llm_measure_code': None,
            'llm_time_value': None,
            'llm_time_unit': None,
            'llm_time_points': None,
            'llm_confidence': None,
            'llm_notes': '[API_FAILED] LLM API í˜¸ì¶œ ì‹¤íŒ¨.',
            'llm_status': 'API_FAILED',
            'failure_reason': 'API_FAILED'
        } for outcome in outcomes]
    
    # ê²°ê³¼ íŒŒì‹± (ë°°ì—´ë¡œ ì‘ë‹µ ë°›ìŒ)
    results = []
    if isinstance(result, list):
        # outcome_idë¡œ ë§¤í•‘
        result_map = {r.get('outcome_id'): r for r in result if 'outcome_id' in r}
        for outcome in outcomes:
            outcome_id = outcome.get('id')
            if outcome_id in result_map:
                r = result_map[outcome_id]
                # time_pointsë¥¼ JSONBë¡œ ë³€í™˜
                time_points = r.get('time_points')
                if time_points and isinstance(time_points, list):
                    time_points_json = json.dumps(time_points)
                else:
                    time_points_json = None
                
                measure_code = r.get('measure_code')
                time_value = r.get('time_value')
                time_unit = r.get('time_unit')
                notes = r.get('notes', '')
                
                # time_frame_raw ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                time_frame_raw = outcome.get('time_frame_raw') or ''
                has_time_frame_raw = bool(time_frame_raw and time_frame_raw.strip())
                
                # ìƒíƒœ ë° ì‹¤íŒ¨ ì´ìœ  ê²°ì •
                status, failure_reason, formatted_notes, final_time_value, final_time_unit = determine_llm_status(
                    measure_code, time_value, time_unit, notes, has_time_frame_raw
                )
                
                results.append({
                    'outcome_id': outcome_id,
                    'llm_measure_code': measure_code,
                    'llm_time_value': final_time_value,
                    'llm_time_unit': final_time_unit,
                    'llm_time_points': time_points_json,
                    'llm_confidence': r.get('confidence'),
                    'llm_notes': formatted_notes,
                    'llm_status': status,
                    'failure_reason': failure_reason
                })
            else:
                # ì‘ë‹µì— outcome_idê°€ ì—†ëŠ” ê²½ìš°
                time_frame_raw = outcome.get('time_frame_raw') or ''
                has_time_frame_raw = bool(time_frame_raw and time_frame_raw.strip())
                status, failure_reason, formatted_notes, final_time_value, final_time_unit = determine_llm_status(
                    None, None, None, '[PARSE_ERROR] LLM ì‘ë‹µì— outcome_idê°€ ì—†ìŒ.', has_time_frame_raw
                )
                results.append({
                    'outcome_id': outcome_id,
                    'llm_measure_code': None,
                    'llm_time_value': final_time_value,
                    'llm_time_unit': final_time_unit,
                    'llm_time_points': None,
                    'llm_confidence': None,
                    'llm_notes': formatted_notes,
                    'llm_status': status,
                    'failure_reason': failure_reason
                })
    else:
        # ë‹¨ì¼ ì‘ë‹µì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
        if outcomes:
            outcome = outcomes[0]
            time_points = result.get('time_points')
            if time_points and isinstance(time_points, list):
                time_points_json = json.dumps(time_points)
            else:
                time_points_json = None
            
            measure_code = result.get('measure_code')
            time_value = result.get('time_value')
            time_unit = result.get('time_unit')
            notes = result.get('notes', '')
            
            # time_frame_raw ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            time_frame_raw = outcome.get('time_frame_raw') or ''
            has_time_frame_raw = bool(time_frame_raw and time_frame_raw.strip())
            
            # ìƒíƒœ ë° ì‹¤íŒ¨ ì´ìœ  ê²°ì •
            status, failure_reason, formatted_notes, final_time_value, final_time_unit = determine_llm_status(
                measure_code, time_value, time_unit, notes, has_time_frame_raw
            )
            
            results.append({
                'outcome_id': outcome.get('id'),
                'llm_measure_code': measure_code,
                'llm_time_value': final_time_value,
                'llm_time_unit': final_time_unit,
                'llm_time_points': time_points_json,
                'llm_confidence': result.get('confidence'),
                'llm_notes': formatted_notes,
                'llm_status': status,
                'failure_reason': failure_reason
            })
    
    return results


def insert_llm_results(conn, outcomes: List[Dict], results: List[Dict]):
    """LLM ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ outcome_llm_preprocessed í…Œì´ë¸”ì— ì‚½ì…"""
    if not results or not outcomes:
        return
    
    # outcomeê³¼ resultë¥¼ outcome_idë¡œ ë§¤í•‘
    result_map = {r['outcome_id']: r for r in results}
    
    insert_data = []
    for outcome in outcomes:
        outcome_id = outcome.get('id')
        result = result_map.get(outcome_id, {})
        
        # VARCHAR ê¸¸ì´ ì œí•œ ì ìš©
        llm_time_unit = result.get('llm_time_unit')
        if llm_time_unit and len(llm_time_unit) > 20:
            llm_time_unit = llm_time_unit[:20]
        
        llm_status = result.get('llm_status')
        if llm_status and len(llm_status) > 20:
            llm_status = llm_status[:20]
        
        failure_reason = result.get('failure_reason')
        if failure_reason and len(failure_reason) > 50:
            failure_reason = failure_reason[:50]
        
        llm_measure_code = result.get('llm_measure_code')
        if llm_measure_code and len(llm_measure_code) > 50:
            llm_measure_code = llm_measure_code[:50]
        
        insert_data.append({
            'nct_id': outcome.get('nct_id'),
            'outcome_type': outcome.get('outcome_type'),
            'outcome_order': outcome.get('outcome_order'),
            'measure_raw': outcome.get('measure_raw'),
            'description_raw': outcome.get('description_raw'),
            'time_frame_raw': outcome.get('time_frame_raw'),
            'phase': outcome.get('phase'),
            'llm_measure_code': llm_measure_code,
            'llm_time_value': result.get('llm_time_value'),
            'llm_time_unit': llm_time_unit,
            'llm_time_points': result.get('llm_time_points'),
            'llm_confidence': result.get('llm_confidence'),
            'llm_notes': result.get('llm_notes'),
            'llm_status': llm_status,
            'failure_reason': failure_reason
        })
    
    insert_sql = """
        INSERT INTO outcome_llm_preprocessed (
            nct_id, outcome_type, outcome_order,
            measure_raw, description_raw, time_frame_raw, phase,
            llm_measure_code, llm_time_value, llm_time_unit, llm_time_points,
            llm_confidence, llm_notes, llm_status, failure_reason, parsing_method
        ) VALUES (
            %(nct_id)s, %(outcome_type)s, %(outcome_order)s,
            %(measure_raw)s, %(description_raw)s, %(time_frame_raw)s, %(phase)s,
            %(llm_measure_code)s, %(llm_time_value)s, %(llm_time_unit)s, 
            %(llm_time_points)s::jsonb, %(llm_confidence)s, %(llm_notes)s, 
            %(llm_status)s, %(failure_reason)s, 'LLM'
        )
        ON CONFLICT (nct_id, outcome_type, outcome_order) 
        DO UPDATE SET
            llm_measure_code = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_measure_code
                ELSE EXCLUDED.llm_measure_code
            END,
            llm_time_value = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_time_value
                ELSE EXCLUDED.llm_time_value
            END,
            llm_time_unit = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_time_unit
                ELSE EXCLUDED.llm_time_unit
            END,
            llm_time_points = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_time_points
                ELSE EXCLUDED.llm_time_points
            END,
            llm_confidence = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_confidence
                ELSE EXCLUDED.llm_confidence
            END,
            llm_notes = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_notes
                ELSE EXCLUDED.llm_notes
            END,
            llm_status = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.llm_status
                ELSE EXCLUDED.llm_status
            END,
            failure_reason = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.failure_reason
                ELSE EXCLUDED.failure_reason
            END,
            updated_at = CASE 
                WHEN outcome_llm_preprocessed.llm_status = 'SUCCESS' THEN outcome_llm_preprocessed.updated_at
                ELSE CURRENT_TIMESTAMP
            END
    """
    
    with conn.cursor() as cur:
        execute_batch(cur, insert_sql, insert_data, page_size=100)
        conn.commit()


def create_table_if_not_exists(conn):
    """outcome_llm_preprocessed í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)"""
    with conn.cursor() as cur:
        # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        cur.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'outcome_llm_preprocessed'
            )
        """)
        exists = cur.fetchone()[0]
        
        if not exists:
            print("[INFO] outcome_llm_preprocessed í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„±í•©ë‹ˆë‹¤...")
            # SQL íŒŒì¼ ì½ê¸°
            sql_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'sql', 'create_outcome_llm_preprocessed.sql')
            if os.path.exists(sql_file):
                with open(sql_file, 'r', encoding='utf-8') as f:
                    sql_content = f.read()
                cur.execute(sql_content)
                conn.commit()
                print("[OK] í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            else:
                print(f"[ERROR] SQL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sql_file}")
                raise FileNotFoundError(f"SQL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sql_file}")
        else:
            print("[INFO] outcome_llm_preprocessed í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    print("=" * 80)
    print("[START] ì „ì²´ ë°ì´í„° LLM ì „ì²˜ë¦¬ ì‹œì‘")
    print("=" * 80)
    
    api_keys = get_api_keys()
    if not api_keys:
        print("\n[ERROR] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("í™˜ê²½ë³€ìˆ˜ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print(f"\n[INFO] ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤: {len(api_keys)}ê°œ")
    print(f"[INFO] ì‚¬ìš© ëª¨ë¸: {GEMINI_MODEL}")
    print(f"[INFO] ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}ê°œ")
    
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    # ì‚¬ìš©ë²•: python llm_preprocess_full.py [limit] [batch_size] [start_batch] [--failed-only|--missing-only|--all]
    limit = None
    custom_batch_size = None
    start_batch = 1
    mode = 'missing'  # ê¸°ë³¸ê°’: ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬
    
    # ì˜µì…˜ íŒŒì‹± (--ë¡œ ì‹œì‘í•˜ëŠ” ì¸ì ë¨¼ì € ì²˜ë¦¬)
    for arg in sys.argv[1:]:
        if arg in ['--failed-only', '--missing-only', '--all']:
            mode = arg.replace('--', '')
            break
    
    # ìˆ«ì ì¸ì íŒŒì‹± (ì˜µì…˜ ì œì™¸)
    num_args = [arg for arg in sys.argv[1:] if arg not in ['--failed-only', '--missing-only', '--all']]
    
    if len(num_args) > 0:
        try:
            limit = int(num_args[0])
        except ValueError:
            pass
    
    if len(num_args) > 1:
        try:
            custom_batch_size = int(num_args[1])
        except ValueError:
            pass
    
    if len(num_args) > 2:
        try:
            start_batch = int(num_args[2])
            if start_batch < 1:
                start_batch = 1
        except ValueError:
            pass
    
    # ëª¨ë“œ ì¶œë ¥
    mode_names = {
        'failed-only': 'ì‹¤íŒ¨í•œ í•­ëª©ë§Œ ì¬ì²˜ë¦¬',
        'missing-only': 'ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬',
        'all': 'ì „ì²´ ì²˜ë¦¬ (ê¸°ì¡´ SUCCESS í•­ëª©ì€ ë³´í˜¸ë¨)'
    }
    print(f"[INFO] ì²˜ë¦¬ ëª¨ë“œ: {mode_names.get(mode, mode)}")
    
    # ë°°ì¹˜ í¬ê¸° ì¡°ì •
    if custom_batch_size and custom_batch_size > 0:
        import llm_config
        llm_config.BATCH_SIZE = custom_batch_size
        print(f"[INFO] ë°°ì¹˜ í¬ê¸°ë¥¼ {custom_batch_size}ê°œë¡œ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.")
    
    if start_batch > 1:
        print(f"[INFO] ë°°ì¹˜ {start_batch}ë²ˆë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
    
    try:
        conn = get_db_connection()
        
        # í…Œì´ë¸” ìƒì„± í™•ì¸
        create_table_if_not_exists(conn)
        
        # ì²˜ë¦¬í•  í•­ëª© ì¡°íšŒ (outcome_rawì—ì„œ ì „ì²´ ë°ì´í„°)
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            if mode == 'failed-only':
                # ì‹¤íŒ¨í•œ í•­ëª©ë§Œ ì¬ì²˜ë¦¬ (SUCCESS ì œì™¸)
                query = """
                    SELECT 
                        or_data.id,
                        or_data.nct_id,
                        or_data.outcome_type,
                        or_data.outcome_order,
                        or_data.measure_raw,
                        or_data.description_raw,
                        or_data.time_frame_raw,
                        or_data.phase
                    FROM outcome_raw or_data
                    INNER JOIN outcome_llm_preprocessed olp
                        ON or_data.nct_id = olp.nct_id
                        AND or_data.outcome_type = olp.outcome_type
                        AND or_data.outcome_order = olp.outcome_order
                    WHERE olp.llm_status != 'SUCCESS'
                    ORDER BY or_data.id
                """
                if limit:
                    query += f" LIMIT {limit}"
                cur.execute(query)
                outcomes = cur.fetchall()
                
            elif mode == 'missing-only':
                # ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬ (outcome_llm_preprocessedì— ì—†ëŠ” í•­ëª©)
                query = """
                    SELECT 
                        or_data.id,
                        or_data.nct_id,
                        or_data.outcome_type,
                        or_data.outcome_order,
                        or_data.measure_raw,
                        or_data.description_raw,
                        or_data.time_frame_raw,
                        or_data.phase
                    FROM outcome_raw or_data
                    LEFT JOIN outcome_llm_preprocessed olp
                        ON or_data.nct_id = olp.nct_id
                        AND or_data.outcome_type = olp.outcome_type
                        AND or_data.outcome_order = olp.outcome_order
                    WHERE olp.nct_id IS NULL
                    ORDER BY or_data.id
                """
                if limit:
                    query += f" LIMIT {limit}"
                cur.execute(query)
                outcomes = cur.fetchall()
                
            else:  # mode == 'all'
                # ì „ì²´ ì²˜ë¦¬ (ê¸°ì¡´ SUCCESS í•­ëª©ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ - INSERT ì‹œ CASE ë¬¸ìœ¼ë¡œ ì²˜ë¦¬)
                query = """
                    SELECT 
                        id,
                        nct_id,
                        outcome_type,
                        outcome_order,
                        measure_raw,
                        description_raw,
                        time_frame_raw,
                        phase
                    FROM outcome_raw
                    ORDER BY id
                """
                if limit:
                    query += f" LIMIT {limit}"
                cur.execute(query)
                outcomes = cur.fetchall()
        
        total_count = len(outcomes)
        print(f"\n[INFO] ì²˜ë¦¬í•  í•­ëª©: {total_count:,}ê°œ")
        
        if total_count == 0:
            print("[INFO] ì²˜ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return
        
        # LLM ì „ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬)
        import llm_config
        actual_batch_size = llm_config.BATCH_SIZE
        print(f"\n[STEP 1] LLM ì „ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {actual_batch_size})...")
        all_results = []
        success_count = 0
        failed_count = 0
        partial_recovered_count = 0
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for batch_start in range(0, total_count, actual_batch_size):
            batch_end = min(batch_start + actual_batch_size, total_count)
            batch_outcomes = outcomes[batch_start:batch_end]
            batch_num = (batch_start // actual_batch_size) + 1
            total_batches = (total_count + actual_batch_size - 1) // actual_batch_size
            
            # start_batch ì˜µì…˜: ì§€ì •ëœ ë°°ì¹˜ë¶€í„° ì‹œì‘
            if batch_num < start_batch:
                print(f"  ë°°ì¹˜ {batch_num}/{total_batches} ê±´ë„ˆëœ€ (start_batch={start_batch})")
                continue
            
            print(f"  ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘: {batch_start + 1:,}~{batch_end:,}ë²ˆì§¸ í•­ëª©")
            
            # ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆëŠ”ì§€ í™•ì¸
            import llm_config
            if llm_config._all_keys_exhausted:
                print(f"\n[ERROR] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ì²˜ë¦¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•œë²ˆì— API í˜¸ì¶œ
            batch_results = preprocess_batch_outcomes(batch_outcomes)
            
            # ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
            if llm_config._all_keys_exhausted:
                print(f"\n[ERROR] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ì²˜ë¦¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
            
            # ê²°ê³¼ ì§‘ê³„
            for result in batch_results:
                all_results.append(result)
                status = result.get('llm_status', '')
                if status == 'SUCCESS':
                    success_count += 1
                elif status == 'PARTIAL_RECOVERED':
                    partial_recovered_count += 1
                    failed_count += 1  # ë¶€ë¶„ ë³µêµ¬ë„ ì‹¤íŒ¨ë¡œ ì¹´ìš´íŠ¸
                else:
                    failed_count += 1
            
            # Rate limiting
            time.sleep(60 / MAX_REQUESTS_PER_MINUTE)
            
            # ë°°ì¹˜ë§ˆë‹¤ DB ì €ì¥
            if batch_results:
                print(f"  ë°°ì¹˜ {batch_num} ê²°ê³¼ ì €ì¥ ì¤‘... ({len(batch_results)}ê°œ)")
                insert_llm_results(conn, batch_outcomes, batch_results)
            
            # ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆìœ¼ë©´ ë°°ì¹˜ ë£¨í”„ë„ ì¤‘ë‹¨
            if llm_config._all_keys_exhausted:
                print(f"\n[ERROR] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
        
        print(f"\n[INFO] ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  ì „ì²´: {total_count:,}ê°œ")
        print(f"  ì„±ê³µ (measure_code + time íŒŒì‹±): {success_count:,}ê°œ ({success_count/total_count*100:.1f}%)")
        print(f"  ì‹¤íŒ¨: {failed_count:,}ê°œ ({failed_count/total_count*100:.1f}%)")
        if partial_recovered_count > 0:
            print(f"  ë¶€ë¶„ ë³µêµ¬: {partial_recovered_count:,}ê°œ")
        
        # ìµœì¢… í†µê³„
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN llm_status = 'SUCCESS' THEN 1 END) as success,
                    COUNT(CASE WHEN llm_status = 'MEASURE_FAILED' THEN 1 END) as measure_failed,
                    COUNT(CASE WHEN llm_status = 'TIMEFRAME_FAILED' THEN 1 END) as timeframe_failed,
                    COUNT(CASE WHEN llm_status = 'BOTH_FAILED' THEN 1 END) as both_failed,
                    COUNT(CASE WHEN llm_status = 'API_FAILED' THEN 1 END) as api_failed,
                    COUNT(CASE WHEN llm_status = 'PARTIAL_RECOVERED' THEN 1 END) as partial_recovered,
                    COUNT(llm_measure_code) as with_measure,
                    COUNT(llm_time_value) as with_time,
                    COUNT(CASE WHEN llm_measure_code IS NOT NULL AND llm_time_value IS NOT NULL THEN 1 END) as complete
                FROM outcome_llm_preprocessed
            """)
            stats = cur.fetchone()
            print(f"\n[ìµœì¢… í†µê³„]")
            print(f"  ì €ì¥ëœ í•­ëª©: {stats['total']:,}ê°œ")
            print(f"\n[ìƒíƒœë³„ í†µê³„]")
            print(f"  ì„±ê³µ (SUCCESS): {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
            print(f"  Measure ì‹¤íŒ¨: {stats['measure_failed']:,}ê°œ ({stats['measure_failed']/stats['total']*100:.1f}%)")
            print(f"  Timeframe ì‹¤íŒ¨: {stats['timeframe_failed']:,}ê°œ ({stats['timeframe_failed']/stats['total']*100:.1f}%)")
            print(f"  ëª¨ë‘ ì‹¤íŒ¨: {stats['both_failed']:,}ê°œ ({stats['both_failed']/stats['total']*100:.1f}%)")
            print(f"  API ì‹¤íŒ¨: {stats['api_failed']:,}ê°œ ({stats['api_failed']/stats['total']*100:.1f}%)")
            if stats['partial_recovered'] > 0:
                print(f"  ë¶€ë¶„ ë³µêµ¬: {stats['partial_recovered']:,}ê°œ ({stats['partial_recovered']/stats['total']*100:.1f}%)")
            print(f"\n[ì¶”ì¶œ í†µê³„]")
            print(f"  measure_code ì¶”ì¶œ: {stats['with_measure']:,}ê°œ ({stats['with_measure']/stats['total']*100:.1f}%)")
            print(f"  time ì¶”ì¶œ: {stats['with_time']:,}ê°œ ({stats['with_time']/stats['total']*100:.1f}%)")
            print(f"  ì™„ì „ íŒŒì‹±: {stats['complete']:,}ê°œ ({stats['complete']/stats['total']*100:.1f}%)")
        
        conn.close()
        
    except Exception as e:
        print(f"\n[ERROR] ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        if 'conn' in locals():
            conn.close()


if __name__ == "__main__":
    main()

