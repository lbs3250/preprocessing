"""
ì „ì²´ ë°ì´í„° LLM ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (Inclusion/Exclusion)

inclusion_exclusion_raw í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ LLMìœ¼ë¡œ ì „ì²˜ë¦¬í•˜ì—¬ 
inclusion_exclusion_llm_preprocessed í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import json
import time
from typing import Dict, Optional, List
import psycopg2
from psycopg2.extras import RealDictCursor, execute_batch
from dotenv import load_dotenv
from llm_config import (
    get_api_keys, get_client, switch_to_next_api_key, GEMINI_MODEL,
    MAX_REQUESTS_PER_MINUTE, BATCH_SIZE, MAX_RETRIES, RETRY_DELAY
)
from llm_prompts import get_inclusion_exclusion_preprocess_prompt

load_dotenv()

DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'clinicaltrials'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', '')
}

ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


def get_db_connection():
    """PostgreSQL ì—°ê²° ìƒì„±"""
    return psycopg2.connect(**DB_CONFIG)


def call_gemini_api(prompt: str, nct_id_list: List[str] = None) -> Optional[List]:
    """Gemini API í˜¸ì¶œ (ì—¬ëŸ¬ API í‚¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„, 429 ì—ëŸ¬ ì‹œ ìë™ ì „í™˜)"""
    api_keys = get_api_keys()
    if not api_keys:
        print("[ERROR] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        return None
    
    # í˜„ì¬ ì „ì—­ í‚¤ ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘
    import llm_config
    start_key_index = llm_config._current_key_index
    
    last_error = None
    
    # í˜„ì¬ í‚¤ë¶€í„° ì‹œì‘ (429 ì—ëŸ¬ ì‹œì—ë§Œ ë‹¤ìŒ í‚¤ë¡œ ì „í™˜)
    key_index = start_key_index
    api_key = api_keys[key_index]
    
    try:
        client = get_client(api_key)
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt,
            config={'temperature': 0.0}  # ì „ì²˜ë¦¬ëŠ” deterministicí•˜ê²Œ
        )
        
        content = response.text.strip()
        
        # ì½”ë“œ ë¸”ë¡ ì œê±° (```json ë˜ëŠ” ```ë¡œ ê°ì‹¸ì§„ ê²½ìš°)
        if '```' in content:
            import re
            # ì½”ë“œ ë¸”ë¡ íŒ¨í„´ ë§¤ì¹­
            code_block_pattern = r'```(?:json)?\s*\n(.*?)\n```'
            match = re.search(code_block_pattern, content, re.DOTALL)
            if match:
                content = match.group(1).strip()
            else:
                # ë‹¨ìˆœíˆ ``` ì œê±°
                content = re.sub(r'```(?:json)?', '', content).strip()
        
        # JSON ë°°ì—´ ì‹œì‘ ë¶€ë¶„ ì°¾ê¸° (ì²« ë²ˆì§¸ '[' ìœ„ì¹˜)
        json_start = content.find('[')
        if json_start >= 0:
            content = content[json_start:]
        else:
            # '['ê°€ ì—†ìœ¼ë©´ JSON ê°ì²´ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
            json_start = content.find('{')
            if json_start >= 0:
                # ë‹¨ì¼ ê°ì²´ë¥¼ ë°°ì—´ë¡œ ê°ì‹¸ê¸°
                content = '[' + content[json_start:]
                # ë§ˆì§€ë§‰ '}' ë’¤ì— ']' ì¶”ê°€
                json_end = content.rfind('}')
                if json_end >= 0:
                    content = content[:json_end + 1] + ']'
        
        # JSON ë°°ì—´ ë ë¶€ë¶„ ì°¾ê¸° (ë§ˆì§€ë§‰ ']' ìœ„ì¹˜)
        json_end = content.rfind(']')
        if json_end >= 0:
            content = content[:json_end + 1]
        
        # ì•ë’¤ ê³µë°± ë° ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        content = content.strip()
        
        try:
            parsed = json.loads(content)
            # ë°°ì—´ì´ ì•„ë‹Œ ê²½ìš° ë°°ì—´ë¡œ ë³€í™˜
            if not isinstance(parsed, list):
                parsed = [parsed]
            # ì„±ê³µ ì‹œ í˜„ì¬ í‚¤ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            llm_config._current_key_index = key_index
            return parsed
        except json.JSONDecodeError as e:
            # "Extra data" ì—ëŸ¬ì˜ ê²½ìš° ì²« ë²ˆì§¸ JSONì„ ì¶”ì¶œ ì‹œë„
            if "Extra data" in str(e) or "Expecting" in str(e):
                try:
                    import re
                    # ì²« ë²ˆì§¸ ì™„ì „í•œ JSON ë°°ì—´ë§Œ ì¶”ì¶œ (ë” robustí•œ íŒ¨í„´)
                    # ì¤‘ê´„í˜¸ì™€ ëŒ€ê´„í˜¸ ê· í˜•ì„ ê³ ë ¤í•˜ì—¬ ì™„ì „í•œ ë°°ì—´ ì¶”ì¶œ
                    bracket_count = 0
                    brace_count = 0
                    array_start = -1
                    array_end = -1
                    
                    for i, char in enumerate(content):
                        if char == '[':
                            if bracket_count == 0:
                                array_start = i
                            bracket_count += 1
                        elif char == ']':
                            bracket_count -= 1
                            if bracket_count == 0 and array_start >= 0:
                                array_end = i
                                break
                        elif char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                    
                    if array_start >= 0 and array_end >= 0:
                        first_json = content[array_start:array_end + 1]
                        parsed = json.loads(first_json)
                        if not isinstance(parsed, list):
                            parsed = [parsed]
                        print(f"  [ë³µêµ¬] Extra data/Expecting ì—ëŸ¬ì—ì„œ ì²« ë²ˆì§¸ JSON ë°°ì—´ ì¶”ì¶œ ì„±ê³µ ({len(parsed)}ê°œ í•­ëª©)")
                        # ë³µêµ¬ ì„±ê³µ ì‹œ í˜„ì¬ í‚¤ ì¸ë±ìŠ¤ ìœ ì§€
                        llm_config._current_key_index = key_index
                        return parsed
                except Exception as extra_data_error:
                    print(f"  [Extra data ë³µêµ¬ ì‹¤íŒ¨] {extra_data_error}")
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ íŒŒì‹± ì‹œë„
            print(f"[WARN] JSON íŒŒì‹± ì‹¤íŒ¨ (í‚¤ {key_index + 1}/{len(api_keys)}): {e}")
            print(f"  ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {content[:500]}")
            
            # ì˜ë¦° JSON ë³µêµ¬ ì‹œë„
            try:
                import re
                parsed_items = []
                
                # ë°©ë²• 1: ë°°ì—´ì˜ ê° ìš”ì†Œë¥¼ ì¶”ì¶œ (ìµœìƒìœ„ ë ˆë²¨ ê°ì²´ë§Œ)
                # '{'ì™€ '}'ë¥¼ ì¶”ì í•˜ì—¬ ì™„ì „í•œ ìµœìƒìœ„ ë ˆë²¨ JSON ê°ì²´ ì°¾ê¸°
                brace_count = 0
                bracket_count = 0  # ë°°ì—´ ë ˆë²¨ ì¶”ì 
                start_pos = -1
                current_obj = ""
                in_array = False
                
                for i, char in enumerate(content):
                    if char == '[':
                        bracket_count += 1
                        if bracket_count == 1:
                            in_array = True
                    elif char == ']':
                        bracket_count -= 1
                        if bracket_count == 0:
                            in_array = False
                    elif char == '{':
                        if brace_count == 0 and in_array:
                            start_pos = i
                        brace_count += 1
                        if start_pos >= 0:
                            current_obj += char
                    elif char == '}':
                        if start_pos >= 0:
                            current_obj += char
                        brace_count -= 1
                        if brace_count == 0 and start_pos >= 0:
                            # ì™„ì „í•œ ìµœìƒìœ„ ë ˆë²¨ ê°ì²´ ë°œê²¬
                            try:
                                obj = json.loads(current_obj)
                                if isinstance(obj, dict) and 'nct_id' in obj:
                                    parsed_items.append(obj)
                            except json.JSONDecodeError:
                                pass
                            current_obj = ""
                            start_pos = -1
                    elif start_pos >= 0:
                        current_obj += char
                
                # ë°©ë²• 2: ì •ê·œì‹ìœ¼ë¡œ ìµœìƒìœ„ ë ˆë²¨ ê°ì²´ ì°¾ê¸° (ì¤‘ì²© êµ¬ì¡° ê³ ë ¤)
                if not parsed_items:
                    # ë°°ì—´ ë‚´ë¶€ì˜ ìµœìƒìœ„ ê°ì²´ë§Œ ë§¤ì¹­ (ì¤‘ê´„í˜¸ ê· í˜• ì¶”ì )
                    pattern = r'\{[^{}]*(?:\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}[^{}]*)*\}'
                    json_objects = re.findall(pattern, content, re.DOTALL)
                    for obj_str in json_objects:
                            try:
                                obj = json.loads(obj_str)
                                if isinstance(obj, dict):
                                    # nct_idê°€ ìˆê³  ìœ íš¨í•œ ê²½ìš°ë§Œ ì¶”ê°€
                                    nct_id = obj.get('nct_id')
                                    if nct_id and isinstance(nct_id, str):
                                        # ì¤‘ë³µ ì²´í¬
                                        if not any(item.get('nct_id') == nct_id for item in parsed_items):
                                            parsed_items.append(obj)
                            except json.JSONDecodeError:
                                continue
                
                # ë°©ë²• 3: ë°°ì—´ ì‹œì‘ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ íŒŒì‹± ì‹œë„ (ì ì§„ì  íŒŒì‹±)
                if not parsed_items:
                    # '[' ì´í›„ì˜ ê° ê°ì²´ë¥¼ ê°œë³„ì ìœ¼ë¡œ íŒŒì‹± ì‹œë„
                    array_start = content.find('[')
                    if array_start >= 0:
                        remaining = content[array_start + 1:]
                        brace_count = 0
                        obj_start = -1
                        obj_content = ""
                        
                        for i, char in enumerate(remaining):
                            if char == '{':
                                if brace_count == 0:
                                    obj_start = i
                                brace_count += 1
                                if obj_start >= 0:
                                    obj_content += char
                            elif char == '}':
                                if obj_start >= 0:
                                    obj_content += char
                                brace_count -= 1
                                if brace_count == 0 and obj_start >= 0:
                                    try:
                                        obj = json.loads(obj_content)
                                        if isinstance(obj, dict):
                                            # nct_idê°€ ìˆê³  ìœ íš¨í•œ ê²½ìš°ë§Œ ì¶”ê°€
                                            nct_id = obj.get('nct_id')
                                            if nct_id and isinstance(nct_id, str):
                                                # ì¤‘ë³µ ì²´í¬
                                                if not any(item.get('nct_id') == nct_id for item in parsed_items):
                                                    parsed_items.append(obj)
                                    except json.JSONDecodeError:
                                        pass
                                    obj_content = ""
                                    obj_start = -1
                            elif obj_start >= 0:
                                obj_content += char
                
                if parsed_items:
                    print(f"  [ë³µêµ¬] {len(parsed_items)}ê°œ í•­ëª©ì„ ë¶€ë¶„ íŒŒì‹±í•˜ì—¬ ë³µêµ¬í–ˆìŠµë‹ˆë‹¤.")
                    # ë³µêµ¬ëœ í•­ëª©ì— ë³µêµ¬ í‘œì‹œ ì¶”ê°€ ë° nct_id ê²€ì¦/ë³µêµ¬
                    valid_items = []
                    for idx, item in enumerate(parsed_items):
                        nct_id = item.get('nct_id')
                        # nct_idê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ë³µêµ¬ ì‹œë„
                        if not nct_id or not isinstance(nct_id, str) or not nct_id.strip():
                            # nct_id_listê°€ ì „ë‹¬ëœ ê²½ìš° ìˆœì„œ ê¸°ë°˜ ë³µêµ¬
                            if nct_id_list and idx < len(nct_id_list):
                                nct_id = nct_id_list[idx]
                                item['nct_id'] = nct_id
                                print(f"  [ë³µêµ¬] nct_id ëˆ„ë½ í•­ëª©ì„ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ë³µêµ¬: {nct_id} (ì¸ë±ìŠ¤ {idx})")
                            else:
                                print(f"  [ê²½ê³ ] ë³µêµ¬ëœ í•­ëª©ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ nct_id ë°œê²¬ (ì¸ë±ìŠ¤ {idx}): {nct_id}")
                                continue
                        
                        if nct_id and isinstance(nct_id, str) and nct_id.strip():
                            if 'llm_notes' in item:
                                item['llm_notes'] = f"[PARTIAL_RECOVERED] {item.get('llm_notes', '')}"
                            else:
                                item['llm_notes'] = '[PARTIAL_RECOVERED] JSON íŒŒì‹± ì‹¤íŒ¨ í›„ ë¶€ë¶„ ë³µêµ¬ ì„±ê³µ.'
                            valid_items.append(item)
                    # ë³µêµ¬ ì„±ê³µ ì‹œ í˜„ì¬ í‚¤ ì¸ë±ìŠ¤ ìœ ì§€
                    llm_config._current_key_index = key_index
                    return valid_items if valid_items else None
            except Exception as recover_error:
                print(f"  [ë³µêµ¬ ì‹¤íŒ¨] {recover_error}")
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ëŠ” API í˜¸ì¶œ ì„±ê³µì´ë¯€ë¡œ ê°™ì€ í‚¤ë¥¼ ê³„ì† ì‚¬ìš©
            # í‚¤ ì¸ë±ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šê³  None ë°˜í™˜
            print(f"  [INFO] JSON íŒŒì‹± ì‹¤íŒ¨í–ˆì§€ë§Œ API í˜¸ì¶œì€ ì„±ê³µ. ê°™ì€ í‚¤({key_index + 1}/{len(api_keys)})ë¥¼ ê³„ì† ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return None
    
    except Exception as e:
        error_str = str(e)
        last_error = e
        
        # 429 ì—ëŸ¬ (RESOURCE_EXHAUSTED) ì²´í¬ - ì´ ê²½ìš°ì—ë§Œ ë‹¤ìŒ í‚¤ë¡œ ì „í™˜
        if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str.upper():
            print(f"âš ï¸  API í‚¤ {key_index + 1}/{len(api_keys)}ì—ì„œ 429 ì—ëŸ¬ ë°œìƒ: {error_str}")
            
            # ëª¨ë“  í‚¤ë¥¼ ì‹œë„
            for attempt in range(len(api_keys)):
                next_key_index = (key_index + attempt + 1) % len(api_keys)
                next_api_key = api_keys[next_key_index]
                
                try:
                    print(f"ğŸ”„ ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜í•©ë‹ˆë‹¤ (í‚¤ {next_key_index + 1}/{len(api_keys)})")
                    client = get_client(next_api_key)
                    response = client.models.generate_content(
                        model=GEMINI_MODEL,
                        contents=prompt,
                        config={'temperature': 0.0}
                    )
                    
                    content = response.text.strip()
                    
                    # ì½”ë“œ ë¸”ë¡ ì œê±°
                    if '```' in content:
                        import re
                        code_block_pattern = r'```(?:json)?\s*\n(.*?)\n```'
                        match = re.search(code_block_pattern, content, re.DOTALL)
                        if match:
                            content = match.group(1).strip()
                        else:
                            content = re.sub(r'```(?:json)?', '', content).strip()
                    
                    # JSON ë°°ì—´ ì‹œì‘/ë ì°¾ê¸°
                    json_start = content.find('[')
                    if json_start >= 0:
                        content = content[json_start:]
                    else:
                        json_start = content.find('{')
                        if json_start >= 0:
                            content = '[' + content[json_start:]
                            json_end = content.rfind('}')
                            if json_end >= 0:
                                content = content[:json_end + 1] + ']'
                    
                    json_end = content.rfind(']')
                    if json_end >= 0:
                        content = content[:json_end + 1]
                    
                    content = content.strip()
                    
                    try:
                        parsed = json.loads(content)
                        if not isinstance(parsed, list):
                            parsed = [parsed]
                        # ì„±ê³µ ì‹œ í‚¤ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
                        llm_config._current_key_index = next_key_index
                        return parsed
                    except json.JSONDecodeError:
                        # JSON íŒŒì‹± ì‹¤íŒ¨ëŠ” ê°™ì€ í‚¤ ê³„ì† ì‚¬ìš©
                        llm_config._current_key_index = next_key_index
                        return None
                        
                except Exception as next_e:
                    next_error_str = str(next_e)
                    if "429" in next_error_str or "RESOURCE_EXHAUSTED" in next_error_str.upper():
                        if attempt == len(api_keys) - 1:
                            print(f"[ERROR] ëª¨ë“  API í‚¤({len(api_keys)}ê°œ)ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            llm_config._previous_key_index = llm_config._current_key_index
                            llm_config._current_key_index = next_key_index
                            llm_config._all_keys_exhausted = True
                            return None
                        continue
                    else:
                        print(f"[ERROR] Gemini API ì˜¤ë¥˜ (í‚¤ {next_key_index + 1}/{len(api_keys)}): {next_error_str}")
                        return None
            
            print(f"[ERROR] ëª¨ë“  API í‚¤({len(api_keys)}ê°œ) ì‹œë„ ì‹¤íŒ¨.")
            llm_config._all_keys_exhausted = True
            return None
        else:
            print(f"[ERROR] Gemini API ì˜¤ë¥˜ (í‚¤ {key_index + 1}/{len(api_keys)}): {error_str}")
            return None


def determine_llm_status(inclusion_result, exclusion_result, notes: str = None) -> tuple:
    """
    LLM ì²˜ë¦¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒíƒœì™€ ì‹¤íŒ¨ ì´ìœ  ê²°ì •
    
    Args:
        inclusion_result: Inclusion Criteria êµ¬ì¡°í™” ê²°ê³¼ (ë°°ì—´ ë˜ëŠ” None)
        exclusion_result: Exclusion Criteria êµ¬ì¡°í™” ê²°ê³¼ (ë°°ì—´ ë˜ëŠ” None)
        notes: LLM ì‘ë‹µì˜ notes
    
    Returns:
        (llm_status, failure_reason, formatted_notes)
    """
    has_inclusion = inclusion_result is not None and (
        (isinstance(inclusion_result, list) and len(inclusion_result) > 0) or
        (isinstance(inclusion_result, dict))
    )
    # exclusionì´ ë¹ˆ ë°°ì—´([])ì¸ ê²½ìš°ëŠ” ì •ìƒìœ¼ë¡œ ì²˜ë¦¬ (ì›ë³¸ì— exclusionì´ ì—†ì„ ìˆ˜ ìˆìŒ)
    has_exclusion = exclusion_result is not None and (
        (isinstance(exclusion_result, list)) or  # ë¹ˆ ë°°ì—´ë„ ì •ìƒ
        (isinstance(exclusion_result, dict))
    )
    
    # notes í˜•ì‹í™”
    formatted_notes = notes or ''
    
    if has_inclusion and has_exclusion:
        status = 'SUCCESS'
        failure_reason = None
        if not formatted_notes:
            exclusion_count = len(exclusion_result) if isinstance(exclusion_result, list) else 0
            if exclusion_count == 0:
                formatted_notes = '[SUCCESS] Inclusion êµ¬ì¡°í™” ì„±ê³µ. Exclusion ì—†ìŒ (ì •ìƒ).'
            else:
                formatted_notes = '[SUCCESS] Inclusionê³¼ Exclusion ëª¨ë‘ êµ¬ì¡°í™” ì„±ê³µ.'
    elif not has_inclusion and not has_exclusion:
        status = 'BOTH_FAILED'
        failure_reason = 'BOTH_FAILED'
        if not formatted_notes:
            formatted_notes = '[BOTH_FAILED] Inclusionê³¼ Exclusion ëª¨ë‘ êµ¬ì¡°í™” ì‹¤íŒ¨.'
    elif not has_inclusion:
        status = 'INCLUSION_FAILED'
        failure_reason = 'INCLUSION_FAILED'
        if not formatted_notes:
            formatted_notes = '[INCLUSION_FAILED] Inclusion êµ¬ì¡°í™” ì‹¤íŒ¨.'
    else:  # has_inclusion but not has_exclusion (exclusion_resultê°€ Noneì¸ ê²½ìš°ë§Œ ì‹¤íŒ¨)
        # exclusion_resultê°€ ë¹ˆ ë°°ì—´([])ì¸ ê²½ìš°ëŠ” ì´ë¯¸ has_exclusion=Trueë¡œ ì²˜ë¦¬ë¨
        status = 'EXCLUSION_FAILED'
        failure_reason = 'EXCLUSION_FAILED'
        if not formatted_notes:
            formatted_notes = '[EXCLUSION_FAILED] Exclusion êµ¬ì¡°í™” ì‹¤íŒ¨.'
    
    return status, failure_reason, formatted_notes


def preprocess_batch_eligibility(eligibility_list: List[Dict]) -> List[Dict]:
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ eligibilityCriteriaë¥¼ LLMìœ¼ë¡œ ì „ì²˜ë¦¬"""
    if not eligibility_list:
        return []
    
    # nct_id ëª©ë¡ ìƒì„± (ë³µêµ¬ ì‹œ ì‚¬ìš©)
    nct_id_list = [e.get('nct_id') for e in eligibility_list if e.get('nct_id')]
    
    # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    items = []
    for eligibility in eligibility_list:
        nct_id = eligibility.get('nct_id')
        criteria_raw = eligibility.get('eligibility_criteria_raw', '') or ''
        # ë¹ˆ ê°’ ìƒëµí•˜ì—¬ ë” ì§§ê²Œ
        parts = [f"{nct_id}"]
        if criteria_raw:
            parts.append(f"{criteria_raw}")
        item_str = "|".join(parts)
        items.append(item_str)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    items_text = '\n'.join(items)
    prompt = get_inclusion_exclusion_preprocess_prompt(items_text)
    
    result = call_gemini_api(prompt, nct_id_list)
    
    if not result:
        # API ì‹¤íŒ¨ ì‹œ ëª¨ë‘ null ì²˜ë¦¬
        return [{
            'nct_id': eligibility.get('nct_id'),
            'inclusion_criteria': None,
            'exclusion_criteria': None,
            'llm_confidence': None,
            'llm_notes': '[API_FAILED] LLM API í˜¸ì¶œ ì‹¤íŒ¨.',
            'llm_status': 'API_FAILED',
            'failure_reason': 'API_FAILED'
        } for eligibility in eligibility_list]
    
    # ê²°ê³¼ íŒŒì‹± (ë°°ì—´ë¡œ ì‘ë‹µ ë°›ìŒ)
    results = []
    if isinstance(result, list):
        # nct_idê°€ ì—†ëŠ” í•­ëª©ë“¤ì„ ë³µêµ¬ ì‹œë„
        for r in result:
            if not r.get('nct_id') or not isinstance(r.get('nct_id'), str):
                # nct_idê°€ ì—†ìœ¼ë©´, ì›ë³¸ ë°ì´í„°ì™€ ìˆœì„œë¥¼ ë§¤ì¹­ ì‹œë„
                # (ë°°ì¹˜ ë‚´ì—ì„œ ìˆœì„œê°€ ìœ ì§€ëœë‹¤ê³  ê°€ì •)
                idx = result.index(r)
                if idx < len(nct_id_list):
                    r['nct_id'] = nct_id_list[idx]
                    print(f"  [ë³µêµ¬] nct_id ëˆ„ë½ í•­ëª©ì„ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ë³µêµ¬: {r['nct_id']}")
        
        # nct_idë¡œ ë§¤í•‘ (nct_idê°€ ìˆê³  ìœ íš¨í•œ ê²ƒë§Œ)
        result_map = {}
        unmatched_results = []  # nct_idê°€ ì—†ëŠ” ê²°ê³¼ë“¤
        for idx, r in enumerate(result):
            nct_id = r.get('nct_id')
            if nct_id and isinstance(nct_id, str):
                # ì¤‘ë³µì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ê²ƒë§Œ ì‚¬ìš©
                if nct_id not in result_map:
                    result_map[nct_id] = r
                else:
                    print(f"  [ê²½ê³ ] ì¤‘ë³µëœ nct_id ë°œê²¬: {nct_id}, ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš©")
            else:
                # nct_idê°€ ì—†ìœ¼ë©´ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ë³µêµ¬ ì‹œë„
                if idx < len(nct_id_list):
                    recovered_nct_id = nct_id_list[idx]
                    r['nct_id'] = recovered_nct_id
                    result_map[recovered_nct_id] = r
                    print(f"  [ë³µêµ¬] ë§¤í•‘ ë‹¨ê³„ì—ì„œ nct_id ë³µêµ¬: {recovered_nct_id} (ì¸ë±ìŠ¤ {idx})")
                else:
                    unmatched_results.append((idx, r))
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ ë³µêµ¬ ì‹œë„
        if unmatched_results:
            used_indices = set()
            for idx, r in unmatched_results:
                # ì´ë¯¸ ì‚¬ìš©ëœ ì¸ë±ìŠ¤ ì œì™¸í•˜ê³  ìˆœì„œëŒ€ë¡œ í• ë‹¹
                for i, nct_id in enumerate(nct_id_list):
                    if i not in used_indices and nct_id not in result_map:
                        r['nct_id'] = nct_id
                        result_map[nct_id] = r
                        used_indices.add(i)
                        print(f"  [ë³µêµ¬] ë§¤í•‘ ì‹¤íŒ¨ í•­ëª©ì„ ìˆœì„œ ê¸°ë°˜ìœ¼ë¡œ ë³µêµ¬: {nct_id} (ì¸ë±ìŠ¤ {i})")
                        break
        
        for eligibility in eligibility_list:
            nct_id = eligibility.get('nct_id')
            if nct_id in result_map:
                r = result_map[nct_id]
                # inclusion_criteriaì™€ exclusion_criteriaë¥¼ JSONBë¡œ ë³€í™˜
                inclusion_criteria = r.get('inclusion_criteria')
                exclusion_criteria = r.get('exclusion_criteria')
                
                # ë¹ˆ ë°°ì—´ë„ JSONìœ¼ë¡œ ë³€í™˜ (Noneì´ ì•„ë‹Œ ë¹ˆ ë°°ì—´ë¡œ ì €ì¥)
                inclusion_json = json.dumps(inclusion_criteria) if inclusion_criteria is not None else None
                exclusion_json = json.dumps(exclusion_criteria) if exclusion_criteria is not None else None
                
                notes = r.get('notes', '')
                
                # ìƒíƒœ ë° ì‹¤íŒ¨ ì´ìœ  ê²°ì •
                status, failure_reason, formatted_notes = determine_llm_status(
                    inclusion_criteria, exclusion_criteria, notes
                )
                
                results.append({
                    'nct_id': nct_id,
                    'inclusion_criteria': inclusion_json,
                    'exclusion_criteria': exclusion_json,
                    'llm_confidence': r.get('confidence'),
                    'llm_notes': formatted_notes,
                    'llm_status': status,
                    'failure_reason': failure_reason
                })
            else:
                # ì‘ë‹µì— nct_idê°€ ì—†ëŠ” ê²½ìš° (ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨)
                status, failure_reason, formatted_notes = determine_llm_status(
                    None, None, '[PARSE_ERROR] LLM ì‘ë‹µì— nct_idê°€ ì—†ìŒ. ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨.'
                )
                results.append({
                    'nct_id': nct_id,
                    'inclusion_criteria': None,
                    'exclusion_criteria': None,
                    'llm_confidence': None,
                    'llm_notes': formatted_notes,
                    'llm_status': status,
                    'failure_reason': failure_reason
                })
    else:
        # ë‹¨ì¼ ì‘ë‹µì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
        if eligibility_list:
            eligibility = eligibility_list[0]
            inclusion_criteria = result.get('inclusion_criteria')
            exclusion_criteria = result.get('exclusion_criteria')
            
            # ë¹ˆ ë°°ì—´ë„ JSONìœ¼ë¡œ ë³€í™˜ (Noneì´ ì•„ë‹Œ ë¹ˆ ë°°ì—´ë¡œ ì €ì¥)
            inclusion_json = json.dumps(inclusion_criteria) if inclusion_criteria is not None else None
            exclusion_json = json.dumps(exclusion_criteria) if exclusion_criteria is not None else None
            
            notes = result.get('notes', '')
            
            # ìƒíƒœ ë° ì‹¤íŒ¨ ì´ìœ  ê²°ì •
            status, failure_reason, formatted_notes = determine_llm_status(
                inclusion_criteria, exclusion_criteria, notes
            )
            
            results.append({
                'nct_id': eligibility.get('nct_id'),
                'inclusion_criteria': inclusion_json,
                'exclusion_criteria': exclusion_json,
                'llm_confidence': result.get('confidence'),
                'llm_notes': formatted_notes,
                'llm_status': status,
                'failure_reason': failure_reason
            })
    
    return results


def insert_llm_results(conn, eligibility_list: List[Dict], results: List[Dict]):
    """LLM ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ inclusion_exclusion_llm_preprocessed í…Œì´ë¸”ì— ì‚½ì…"""
    if not results or not eligibility_list:
        return
    
    # eligibilityì™€ resultë¥¼ nct_idë¡œ ë§¤í•‘
    result_map = {r['nct_id']: r for r in results}
    
    insert_data = []
    for eligibility in eligibility_list:
        nct_id = eligibility.get('nct_id')
        result = result_map.get(nct_id, {})
        
        # VARCHAR ê¸¸ì´ ì œí•œ ì ìš©
        llm_status = result.get('llm_status')
        if llm_status and len(llm_status) > 20:
            llm_status = llm_status[:20]
        
        failure_reason = result.get('failure_reason')
        if failure_reason and len(failure_reason) > 50:
            failure_reason = failure_reason[:50]
        
        insert_data.append({
            'nct_id': nct_id,
            'eligibility_criteria_raw': eligibility.get('eligibility_criteria_raw'),
            'phase': eligibility.get('phase'),
            'inclusion_criteria': result.get('inclusion_criteria'),
            'exclusion_criteria': result.get('exclusion_criteria'),
            'llm_confidence': result.get('llm_confidence'),
            'llm_notes': result.get('llm_notes'),
            'llm_status': llm_status,
            'failure_reason': failure_reason
        })
    
    insert_sql = """
        INSERT INTO inclusion_exclusion_llm_preprocessed (
            nct_id, eligibility_criteria_raw, phase,
            inclusion_criteria, exclusion_criteria,
            llm_confidence, llm_notes, llm_status, failure_reason, parsing_method
        ) VALUES (
            %(nct_id)s, %(eligibility_criteria_raw)s, %(phase)s,
            %(inclusion_criteria)s::jsonb, %(exclusion_criteria)s::jsonb,
            %(llm_confidence)s, %(llm_notes)s, %(llm_status)s, %(failure_reason)s, 'LLM'
        )
        ON CONFLICT (nct_id) 
        DO UPDATE SET
            inclusion_criteria = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.inclusion_criteria
                ELSE EXCLUDED.inclusion_criteria
            END,
            exclusion_criteria = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.exclusion_criteria
                ELSE EXCLUDED.exclusion_criteria
            END,
            llm_confidence = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.llm_confidence
                ELSE EXCLUDED.llm_confidence
            END,
            llm_notes = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.llm_notes
                ELSE EXCLUDED.llm_notes
            END,
            llm_status = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.llm_status
                ELSE EXCLUDED.llm_status
            END,
            failure_reason = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.failure_reason
                ELSE EXCLUDED.failure_reason
            END,
            updated_at = CASE 
                WHEN inclusion_exclusion_llm_preprocessed.llm_status = 'SUCCESS' THEN inclusion_exclusion_llm_preprocessed.updated_at
                ELSE CURRENT_TIMESTAMP
            END
    """
    
    with conn.cursor() as cur:
        execute_batch(cur, insert_sql, insert_data, page_size=100)
        conn.commit()


def create_table_if_not_exists(conn):
    """inclusion_exclusion_llm_preprocessed í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)"""
    with conn.cursor() as cur:
        # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        cur.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'inclusion_exclusion_llm_preprocessed'
            )
        """)
        exists = cur.fetchone()[0]
        
        if not exists:
            print("[INFO] inclusion_exclusion_llm_preprocessed í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„±í•©ë‹ˆë‹¤...")
            # SQL íŒŒì¼ ì½ê¸°
            sql_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'sql', 'create_inclusion_exclusion_llm_preprocessed.sql')
            if os.path.exists(sql_file):
                with open(sql_file, 'r', encoding='utf-8') as f:
                    sql_content = f.read()
                cur.execute(sql_content)
                conn.commit()
                print("[OK] í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            else:
                print(f"[ERROR] SQL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sql_file}")
                raise FileNotFoundError(f"SQL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sql_file}")
        else:
            print("[INFO] inclusion_exclusion_llm_preprocessed í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    print("=" * 80)
    print("[START] ì „ì²´ ë°ì´í„° LLM ì „ì²˜ë¦¬ ì‹œì‘ (Inclusion/Exclusion)")
    print("=" * 80)
    
    api_keys = get_api_keys()
    if not api_keys:
        print("\n[ERROR] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("í™˜ê²½ë³€ìˆ˜ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print(f"\n[INFO] ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤: {len(api_keys)}ê°œ")
    print(f"[INFO] ì‚¬ìš© ëª¨ë¸: {GEMINI_MODEL}")
    print(f"[INFO] ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}ê°œ")
    
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    # ì‚¬ìš©ë²•: python llm_preprocess_inclusion_exclusion.py [limit] [batch_size] [start_batch] [--failed-only|--missing-only|--all]
    limit = None
    custom_batch_size = None
    start_batch = 1
    mode = 'missing'  # ê¸°ë³¸ê°’: ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬
    
    # ì˜µì…˜ íŒŒì‹± (--ë¡œ ì‹œì‘í•˜ëŠ” ì¸ì ë¨¼ì € ì²˜ë¦¬)
    for arg in sys.argv[1:]:
        if arg in ['--failed-only', '--missing-only', '--all']:
            mode = arg.replace('--', '')
            break
    
    # ìˆ«ì ì¸ì íŒŒì‹± (ì˜µì…˜ ì œì™¸)
    num_args = [arg for arg in sys.argv[1:] if arg not in ['--failed-only', '--missing-only', '--all']]
    
    if len(num_args) > 0:
        try:
            limit = int(num_args[0])
        except ValueError:
            pass
    
    if len(num_args) > 1:
        try:
            custom_batch_size = int(num_args[1])
        except ValueError:
            pass
    
    if len(num_args) > 2:
        try:
            start_batch = int(num_args[2])
            if start_batch < 1:
                start_batch = 1
        except ValueError:
            pass
    
    # ëª¨ë“œ ì¶œë ¥
    mode_names = {
        'failed-only': 'ì‹¤íŒ¨í•œ í•­ëª©ë§Œ ì¬ì²˜ë¦¬',
        'missing-only': 'ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬',
        'all': 'ì „ì²´ ì²˜ë¦¬ (ê¸°ì¡´ SUCCESS í•­ëª©ì€ ë³´í˜¸ë¨)'
    }
    print(f"[INFO] ì²˜ë¦¬ ëª¨ë“œ: {mode_names.get(mode, mode)}")
    
    # ë°°ì¹˜ í¬ê¸° ì¡°ì •
    if custom_batch_size and custom_batch_size > 0:
        import llm_config
        llm_config.BATCH_SIZE = custom_batch_size
        print(f"[INFO] ë°°ì¹˜ í¬ê¸°ë¥¼ {custom_batch_size}ê°œë¡œ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.")
    
    if start_batch > 1:
        print(f"[INFO] ë°°ì¹˜ {start_batch}ë²ˆë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
    
    try:
        conn = get_db_connection()
        
        # í…Œì´ë¸” ìƒì„± í™•ì¸
        create_table_if_not_exists(conn)
        
        # ì²˜ë¦¬í•  í•­ëª© ì¡°íšŒ (inclusion_exclusion_rawì—ì„œ ì „ì²´ ë°ì´í„°)
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            if mode == 'failed-only':
                # ì‹¤íŒ¨í•œ í•­ëª©ë§Œ ì¬ì²˜ë¦¬ (SUCCESS ì œì™¸)
                query = """
                    SELECT 
                        ier.nct_id,
                        ier.eligibility_criteria_raw,
                        ier.phase
                    FROM inclusion_exclusion_raw ier
                    INNER JOIN inclusion_exclusion_llm_preprocessed iep
                        ON ier.nct_id = iep.nct_id
                    WHERE iep.llm_status != 'SUCCESS'
                    ORDER BY ier.nct_id
                """
                if limit:
                    query += f" LIMIT {limit}"
                cur.execute(query)
                eligibility_list = cur.fetchall()
                
            elif mode == 'missing-only':
                # ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬ (inclusion_exclusion_llm_preprocessedì— ì—†ëŠ” í•­ëª©)
                query = """
                    SELECT 
                        ier.nct_id,
                        ier.eligibility_criteria_raw,
                        ier.phase
                    FROM inclusion_exclusion_raw ier
                    LEFT JOIN inclusion_exclusion_llm_preprocessed iep
                        ON ier.nct_id = iep.nct_id
                    WHERE iep.nct_id IS NULL
                    ORDER BY ier.nct_id
                """
                if limit:
                    query += f" LIMIT {limit}"
                cur.execute(query)
                eligibility_list = cur.fetchall()
                
            else:  # mode == 'all'
                # ì „ì²´ ì²˜ë¦¬ (ê¸°ì¡´ SUCCESS í•­ëª©ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ - INSERT ì‹œ CASE ë¬¸ìœ¼ë¡œ ì²˜ë¦¬)
                query = """
                    SELECT 
                        nct_id,
                        eligibility_criteria_raw,
                        phase
                    FROM inclusion_exclusion_raw
                    ORDER BY nct_id
                """
                if limit:
                    query += f" LIMIT {limit}"
                cur.execute(query)
                eligibility_list = cur.fetchall()
        
        total_count = len(eligibility_list)
        print(f"\n[INFO] ì²˜ë¦¬í•  í•­ëª©: {total_count:,}ê°œ")
        
        if total_count == 0:
            print("[INFO] ì²˜ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return
        
        # LLM ì „ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬)
        import llm_config
        actual_batch_size = llm_config.BATCH_SIZE
        print(f"\n[STEP 1] LLM ì „ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {actual_batch_size})...")
        all_results = []
        success_count = 0
        failed_count = 0
        inclusion_failed_count = 0
        exclusion_failed_count = 0
        both_failed_count = 0
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for batch_start in range(0, total_count, actual_batch_size):
            batch_end = min(batch_start + actual_batch_size, total_count)
            batch_eligibility = eligibility_list[batch_start:batch_end]
            batch_num = (batch_start // actual_batch_size) + 1
            total_batches = (total_count + actual_batch_size - 1) // actual_batch_size
            
            # start_batch ì˜µì…˜: ì§€ì •ëœ ë°°ì¹˜ë¶€í„° ì‹œì‘
            if batch_num < start_batch:
                print(f"  ë°°ì¹˜ {batch_num}/{total_batches} ê±´ë„ˆëœ€ (start_batch={start_batch})")
                continue
            
            print(f"  ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘: {batch_start + 1:,}~{batch_end:,}ë²ˆì§¸ í•­ëª©")
            
            # ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆëŠ”ì§€ í™•ì¸
            import llm_config
            if llm_config._all_keys_exhausted:
                print(f"\n[ERROR] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ì²˜ë¦¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•œë²ˆì— API í˜¸ì¶œ
            batch_results = preprocess_batch_eligibility(batch_eligibility)
            
            # ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
            if llm_config._all_keys_exhausted:
                print(f"\n[ERROR] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ì²˜ë¦¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
            
            # ê²°ê³¼ ì§‘ê³„
            for result in batch_results:
                all_results.append(result)
                status = result.get('llm_status', '')
                if status == 'SUCCESS':
                    success_count += 1
                elif status == 'INCLUSION_FAILED':
                    inclusion_failed_count += 1
                    failed_count += 1
                elif status == 'EXCLUSION_FAILED':
                    exclusion_failed_count += 1
                    failed_count += 1
                elif status == 'BOTH_FAILED':
                    both_failed_count += 1
                    failed_count += 1
                else:
                    failed_count += 1
            
            # Rate limiting
            time.sleep(60 / MAX_REQUESTS_PER_MINUTE)
            
            # ë°°ì¹˜ë§ˆë‹¤ DB ì €ì¥
            if batch_results:
                print(f"  ë°°ì¹˜ {batch_num} ê²°ê³¼ ì €ì¥ ì¤‘... ({len(batch_results)}ê°œ)")
                insert_llm_results(conn, batch_eligibility, batch_results)
            
            # ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆìœ¼ë©´ ë°°ì¹˜ ë£¨í”„ë„ ì¤‘ë‹¨
            if llm_config._all_keys_exhausted:
                print(f"\n[ERROR] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
        
        print(f"\n[INFO] ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  ì „ì²´: {total_count:,}ê°œ")
        print(f"  ì„±ê³µ (Inclusion + Exclusion): {success_count:,}ê°œ ({success_count/total_count*100:.1f}%)")
        print(f"  ì‹¤íŒ¨: {failed_count:,}ê°œ ({failed_count/total_count*100:.1f}%)")
        if inclusion_failed_count > 0:
            print(f"    - Inclusionë§Œ ì‹¤íŒ¨: {inclusion_failed_count:,}ê°œ")
        if exclusion_failed_count > 0:
            print(f"    - Exclusionë§Œ ì‹¤íŒ¨: {exclusion_failed_count:,}ê°œ")
        if both_failed_count > 0:
            print(f"    - ë‘˜ ë‹¤ ì‹¤íŒ¨: {both_failed_count:,}ê°œ")
        
        # ìµœì¢… í†µê³„
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN llm_status = 'SUCCESS' THEN 1 END) as success,
                    COUNT(CASE WHEN llm_status = 'INCLUSION_FAILED' THEN 1 END) as inclusion_failed,
                    COUNT(CASE WHEN llm_status = 'EXCLUSION_FAILED' THEN 1 END) as exclusion_failed,
                    COUNT(CASE WHEN llm_status = 'BOTH_FAILED' THEN 1 END) as both_failed,
                    COUNT(CASE WHEN llm_status = 'API_FAILED' THEN 1 END) as api_failed,
                    COUNT(inclusion_criteria) as with_inclusion,
                    COUNT(exclusion_criteria) as with_exclusion,
                    COUNT(CASE WHEN inclusion_criteria IS NOT NULL AND exclusion_criteria IS NOT NULL THEN 1 END) as complete
                FROM inclusion_exclusion_llm_preprocessed
            """)
            stats = cur.fetchone()
            print(f"\n[ìµœì¢… í†µê³„]")
            print(f"  ì €ì¥ëœ í•­ëª©: {stats['total']:,}ê°œ")
            print(f"\n[ìƒíƒœë³„ í†µê³„]")
            print(f"  ì„±ê³µ (SUCCESS): {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
            print(f"  Inclusion ì‹¤íŒ¨: {stats['inclusion_failed']:,}ê°œ ({stats['inclusion_failed']/stats['total']*100:.1f}%)")
            print(f"  Exclusion ì‹¤íŒ¨: {stats['exclusion_failed']:,}ê°œ ({stats['exclusion_failed']/stats['total']*100:.1f}%)")
            print(f"  ëª¨ë‘ ì‹¤íŒ¨: {stats['both_failed']:,}ê°œ ({stats['both_failed']/stats['total']*100:.1f}%)")
            print(f"  API ì‹¤íŒ¨: {stats['api_failed']:,}ê°œ ({stats['api_failed']/stats['total']*100:.1f}%)")
            print(f"\n[ì¶”ì¶œ í†µê³„]")
            print(f"  Inclusion ì¶”ì¶œ: {stats['with_inclusion']:,}ê°œ ({stats['with_inclusion']/stats['total']*100:.1f}%)")
            print(f"  Exclusion ì¶”ì¶œ: {stats['with_exclusion']:,}ê°œ ({stats['with_exclusion']/stats['total']*100:.1f}%)")
            print(f"  ì™„ì „ íŒŒì‹±: {stats['complete']:,}ê°œ ({stats['complete']/stats['total']*100:.1f}%)")
        
        conn.close()
        
    except Exception as e:
        print(f"\n[ERROR] ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        if 'conn' in locals():
            conn.close()


if __name__ == "__main__":
    main()

